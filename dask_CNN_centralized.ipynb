{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd3346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id.orig_h         float32\n",
      "id.orig_p         float32\n",
      "id.resp_h         float32\n",
      "id.resp_p         float32\n",
      "duration          float32\n",
      "orig_bytes        float32\n",
      "resp_bytes        float32\n",
      "conn_state        float32\n",
      "missed_bytes      float32\n",
      "history           float32\n",
      "orig_pkts         float32\n",
      "orig_ip_bytes     float32\n",
      "resp_pkts         float32\n",
      "resp_ip_bytes     float32\n",
      "detailed-label      int32\n",
      "proto_icmp          int32\n",
      "proto_tcp           int32\n",
      "proto_udp           int32\n",
      "service_dhcp        int32\n",
      "service_dns         int32\n",
      "service_http        int32\n",
      "service_irc         int32\n",
      "service_ssh         int32\n",
      "service_ssl         int32\n",
      "dtype: object\n",
      "        id.orig_h  id.orig_p  id.resp_h  id.resp_p  duration  orig_bytes  \\\n",
      "547395   3.232236   0.686359   1.529949   0.550982       0.0         0.0   \n",
      "547396   3.232236   0.713139   3.111203   0.550982       0.0         0.0   \n",
      "547397   3.232236   0.705803   3.119152   0.550982       0.0         0.0   \n",
      "547398   3.232236   0.500587   0.759364   0.550982       0.0         0.0   \n",
      "547399   3.232236   0.500587   1.526962   0.550982       0.0         0.0   \n",
      "\n",
      "        resp_bytes  conn_state  missed_bytes   history  orig_pkts  \\\n",
      "547395         0.0    0.722481           0.0  0.223978        0.0   \n",
      "547396         0.0    0.722481           0.0  0.223978        0.0   \n",
      "547397         0.0    0.722481           0.0  0.223978        0.0   \n",
      "547398         0.0    0.722481           0.0  0.223978        0.0   \n",
      "547399         0.0    0.722481           0.0  0.223978        0.0   \n",
      "\n",
      "        orig_ip_bytes  resp_pkts  resp_ip_bytes  detailed-label  proto_icmp  \\\n",
      "547395            0.0        0.0            0.0               1           0   \n",
      "547396            0.0        0.0            0.0               1           0   \n",
      "547397            0.0        0.0            0.0               1           0   \n",
      "547398            0.0        0.0            0.0               1           0   \n",
      "547399            0.0        0.0            0.0               1           0   \n",
      "\n",
      "        proto_tcp  proto_udp  service_dhcp  service_dns  service_http  \\\n",
      "547395          1          0             0            0             0   \n",
      "547396          1          0             0            0             0   \n",
      "547397          1          0             0            0             0   \n",
      "547398          1          0             0            0             0   \n",
      "547399          1          0             0            0             0   \n",
      "\n",
      "        service_irc  service_ssh  service_ssl  \n",
      "547395            0            0            0  \n",
      "547396            0            0            0  \n",
      "547397            0            0            0  \n",
      "547398            0            0            0  \n",
      "547399            0            0            0  \n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#### Thay đổi hiển thị ####\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.set_option('display.max_row', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#### Change display ####\n",
    "\n",
    "input_file = [\"/mnt/c/Users/hoang/FileCSV_DACN_2025/shuffle_IoT23.csv\", \"C:\\\\Users\\\\hoang\\\\FileCSV_DACN_2025\\\\shuffle_IoT23.csv\"]\n",
    "\n",
    "if os.name == 'nt':\n",
    "    input_file = input_file[1]\n",
    "else:\n",
    "    input_file = input_file[0]\n",
    "\n",
    "df = dd.read_csv(input_file)\n",
    "# dtype={'detailed-label': 'object'}, assume_missing=True\n",
    "\n",
    "# print(df.columns)\n",
    "dictTypes = {}\n",
    "df = dd.read_csv(input_file)\n",
    "for col in df.columns:\n",
    "    if col.startswith('proto') == True:\n",
    "        dictTypes[col] = 'int32'\n",
    "    elif col.startswith('service_') == True:\n",
    "        dictTypes[col] = 'int32'\n",
    "    # elif col == 'label':\n",
    "    #     dictTypes[col]= 'int32'\n",
    "    elif col.startswith('detailed-label'):\n",
    "        dictTypes[col] = 'int32'\n",
    "    else:\n",
    "        dictTypes[col]='float32'\n",
    "\n",
    "df = dd.read_csv(input_file, dtype = dictTypes)\n",
    "df = df.drop(columns=['label'])\n",
    "\n",
    "# phân loại đa nhãn, k dùng\n",
    "# df = df.replace(r'[N|n][a|A][N|n]', 0)\n",
    "# df = df.replace(np.nan, 0)\n",
    "print(df.dtypes)\n",
    "# print(df['duration'].value_counts().compute())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a9f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['detailed-label'].value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detailed-label\n",
      "Attack                                   9398\n",
      "Okiru-Attack                                3\n",
      "C&C-HeartBeat-Attack                      834\n",
      "PartOfAHorizontalPortScan-Attack            5\n",
      "FileDownload                               18\n",
      "C&C-Mirai                                   2\n",
      "DDoS                                 16108989\n",
      "C&C-FileDownload                           53\n",
      "Okiru                                60938340\n",
      "C&C-HeartBeat                           31528\n",
      "C&C-HeartBeat-FileDownload                 11\n",
      "C&C                                     17657\n",
      "PartOfAHorizontalPortScan           213583302\n",
      "C&C-Torii                                  23\n",
      "0                                    30771095\n",
      "C&C-PartOfAHorizontalPortScan             797\n",
      "Name: count, dtype: int64[pyarrow]\n"
     ]
    }
   ],
   "source": [
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ordered_labels = [0, 1, 2, 3]\n",
    "ordered_counts = [label_counts.get(label, 0) for label in ordered_labels] \n",
    "print(label_counts)\n",
    "labels = [\"Benign\",\"DDoS\",\"DoS\",\"Mirai\"]\n",
    "# Vẽ biểu đồ cột\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(labels, ordered_counts, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Nhãn (Classes)\")\n",
    "plt.ylabel(\"Số lượng mẫu (Frequency)\")\n",
    "plt.title(\"Tỷ lệ nhãn trong Dataset\")\n",
    "plt.xticks(range(len(labels)) ,labels, rotation =45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bd1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/dask_expr/_collection.py:4190: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('detailed-label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "df = df[df['detailed-label'].isin(['Okiru', 'PartOfAHorizontalPortScan', '0'])]\n",
    "\n",
    "label_map = {\n",
    "    '0': 0,\n",
    "    'PartOfAHorizontalPortScan': 1,\n",
    "    'Okiru': 2\n",
    "}\n",
    "\n",
    "df['detailed-label'] = df['detailed-label'].map(label_map).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c803cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id.orig_h         float32\n",
      "id.orig_p         float32\n",
      "id.resp_h         float32\n",
      "id.resp_p         float32\n",
      "duration          float32\n",
      "orig_bytes        float32\n",
      "resp_bytes        float32\n",
      "conn_state        float32\n",
      "missed_bytes      float32\n",
      "history           float32\n",
      "orig_pkts         float32\n",
      "orig_ip_bytes     float32\n",
      "resp_pkts         float32\n",
      "resp_ip_bytes     float32\n",
      "detailed-label      int32\n",
      "proto_icmp          int32\n",
      "proto_tcp           int32\n",
      "proto_udp           int32\n",
      "service_dhcp        int32\n",
      "service_dns         int32\n",
      "service_http        int32\n",
      "service_irc         int32\n",
      "service_ssh         int32\n",
      "service_ssl         int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7216e8",
   "metadata": {},
   "source": [
    "# Generator + Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6b9a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/dask_ml/model_selection/_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
      "  warnings.warn(\n",
      "/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/dask_ml/model_selection/_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow import keras\n",
    "\n",
    "#Global var \n",
    "batch_size = 512\n",
    "ratio_test_all = 0.2\n",
    "\n",
    "from dask_ml.model_selection import train_test_split \n",
    "# Bước 1: Tách 80% train, 20% còn lại (val + test)\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2222865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Len:  23\n"
     ]
    }
   ],
   "source": [
    "features_len = len(df.columns)-1\n",
    "print(\"Feature Len: \",features_len)\n",
    "def dask_to_tf_dataset(dask_df, batch_size, num_classes): \n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch=batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "\n",
    "            X = batch.drop(columns='detailed-label').values.astype(np.float32)\n",
    "            y = batch['detailed-label'].values\n",
    "            y_onehot = to_categorical(y, num_classes=num_classes)  \n",
    "\n",
    "            num_splits = max(1, len(X) // batch_size)  # Đảm bảo không chia nhỏ quá mức\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y_onehot, num_splits)\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, features_len), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.int32),\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc400eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747845466.516584   51638 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2248 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batchSize = 512\n",
    "train_gen = dask_to_tf_dataset(train_df, batchSize, 3).repeat()\n",
    "val_gen = dask_to_tf_dataset(val_df, batchSize, 3).repeat()\n",
    "test_gen = dask_to_tf_dataset(test_df, batchSize, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad31c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps/Epoch:  133157\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n_samples =  np.ceil(train_df.shape[0])\n",
    "steps_per_epoch = int(n_samples / (batchSize))\n",
    "validation_steps = int(steps_per_epoch / (16))\n",
    "print(\"Steps/Epoch: \", steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa3efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (23, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m114,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m180,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">298,115</span> (1.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m298,115\u001b[0m (1.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,347</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m297,347\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747845782.271419   63802 service.cc:152] XLA service 0x7ff5180049b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747845782.272168   63802 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "I0000 00:00:1747845782.339617   63802 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747845782.556028   63802 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-05-21 16:43:05.321363: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13315/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 31ms/step - accuracy: 0.9160 - loss: 0.3965 - val_accuracy: 0.2013 - val_loss: 21.2993\n",
      "Epoch 2/10\n",
      "\u001b[1m13315/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 30ms/step - accuracy: 0.9234 - loss: 0.3957 - val_accuracy: 0.3971 - val_loss: 29.1322\n",
      "Epoch 3/10\n",
      "\u001b[1m13315/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.3615 - val_accuracy: 0.6428 - val_loss: 43.3081\n",
      "Epoch 4/10\n",
      "\u001b[1m13315/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 28ms/step - accuracy: 0.9375 - loss: 0.3391 - val_accuracy: 0.7005 - val_loss: 1.4298\n",
      "Epoch 5/10\n",
      "\u001b[1m13315/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 31ms/step - accuracy: 0.9492 - loss: 0.3458 - val_accuracy: 0.5008 - val_loss: 685.8297\n",
      "Epoch 6/10\n",
      "\u001b[1m13311/13315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9580 - loss: 0.2972"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "########### Enable XLA ###############\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "########### Nếu không dùng XLA ###########\n",
    "# import os\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "\n",
    "# shape\n",
    "features, labels = next(iter(train_gen))\n",
    "input_shape = (features.shape[1], 1)\n",
    "output_shape = labels.shape[1]\n",
    "\n",
    "print(f\"Input Shape: {input_shape}\")\n",
    "\n",
    "# Định nghĩa mô hình CNN\n",
    "# VGG, ...\n",
    "# Conv2D, tabular, ...\n",
    "# HE, tính tương thích của HE với CNN\n",
    "# Tính chất data in, out; Học tăng cường\n",
    "start_time = datetime.now()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv1D(filters=128, kernel_size=7,  padding=\"same\",activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(output_shape, activation='softmax')\n",
    "])\n",
    "adam_optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "#sparse khi không onehot\n",
    "# for batch in dataloader:\n",
    "#     X_batch = batch[:, :-1]\n",
    "#     y_batch = batch[:, -1]\n",
    "#     y_onehot = to_categorical(y_batch, num_classes=10)\n",
    "    \n",
    "#     model.train_on_batch(X_batch, y_onehot, verbose=1)\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger(\"Centralized_Log/\"+ datetime.now().strftime(\"Month %m Day %d __ %Hh--%Mp\")+\".csv\" , append=True)\n",
    "model.fit(train_gen, epochs=10,  validation_data=val_gen, \n",
    "          validation_steps=validation_steps, steps_per_epoch=int(steps_per_epoch/10), verbose = 1, callbacks=[csv_logger])\n",
    "\n",
    "end_time = datetime.now()\n",
    "simulated_time = end_time - start_time\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(\"Centralized_Model/cnn_model_\" + datetime.now().strftime(\"Month %m Day %d __ %Hh--%Mp\")+\".keras\")\n",
    "\n",
    "print(f\"Simulated time: {simulated_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01bbcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "batchSize = 512\n",
    "n_partitions = train_df.npartitions  # Tổng số chunk hiện có\n",
    "print(n_partitions)\n",
    "\n",
    "# # Tạo validation dataset cố định 1 lần\n",
    "# val_df_pd = val_df.compute()\n",
    "# X_val = val_df_pd.drop(columns='detailed-label').values.astype(np.float32)\n",
    "# y_val = tf.keras.utils.to_categorical(val_df_pd['detailed-label'].values, num_classes=3)\n",
    "\n",
    "# del val_df_pd\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "# del X_val\n",
    "# del y_val\n",
    "# val_dataset = val_dataset.batch(batchSize).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def df_partition_to_dataset(dask_partition, num_classes=3, batch_size=512):\n",
    "    df = dask_partition.compute()\n",
    "    if df.empty:\n",
    "        return None\n",
    "    X = df.drop(columns='detailed-label').values.astype(np.float32)\n",
    "    y = tf.keras.utils.to_categorical(df['detailed-label'].values, num_classes)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    return ds.shuffle(len(X)).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training on partition 1/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746379085.743877   39304 service.cc:152] XLA service 0x7f08b4010210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746379085.743948   39304 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2025-05-04 17:18:05.836701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746379086.198713   39304 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   31/20147\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 5ms/step - accuracy: 0.8444 - loss: 0.4347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746379089.397428   39304 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20147/20147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 0.0401 - val_accuracy: 0.9927 - val_loss: 0.0716\n",
      "\n",
      "🔁 Training on partition 2/72\n",
      "\u001b[1m21419/21419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.6914e-04 - val_accuracy: 1.0000 - val_loss: 1.3734e-04\n",
      "\n",
      "🔁 Training on partition 3/72\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(23,1)),\n",
    "    layers.Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv1D(filters=128, kernel_size=7,  padding=\"same\",activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train lần lượt trên từng \n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger(\"Centralized_Log/\"+ datetime.now().strftime(\"Month %m Day %d __ %Hh%Mp\")+\".csv\" , append=True)\n",
    "nepochs=25\n",
    "for epoch in range(nepochs):\n",
    "    for i in range(n_partitions):\n",
    "        print(f\"\\n🔁 Training on partition {i+1}/{n_partitions}\")\n",
    "        train_partition = train_df.get_partition(i)\n",
    "        val_partition = val_df.get_partition(i)\n",
    "        train_ds = df_partition_to_dataset(train_partition, 3, 128)\n",
    "        val_ds = df_partition_to_dataset(val_partition, 3, 128)\n",
    "        if train_ds is not None:\n",
    "            model.fit(train_ds, epochs=1,  validation_data=val_ds, verbose = 1, callbacks=[csv_logger])\n",
    "            \n",
    "end_time = datetime.now()\n",
    "simulated_time = end_time - start_time\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(\"Centralized_Model/cnn_model_\" + datetime.now().strftime(\"Month %m Day %d __ %Hh%Mp\")+\".keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
