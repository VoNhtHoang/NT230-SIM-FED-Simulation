{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16fdc98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748314709.514623    5124 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3686 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/dask_expr/_collection.py:4190: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MI_dir_5_weight', 'MI_dir_5_mean', 'MI_dir_5_std', 'MI_dir_3_weight',\n",
      "       'MI_dir_3_mean', 'MI_dir_3_std', 'MI_dir_1_weight', 'MI_dir_1_mean',\n",
      "       'MI_dir_1_std', 'MI_dir_0.1_weight',\n",
      "       ...\n",
      "       'HpHp_0.1_covariance_0_1', 'HpHp_0.1_pcc_0_1', 'HpHp_0.01_weight_0',\n",
      "       'HpHp_0.01_mean_0', 'HpHp_0.01_std_0', 'HpHp_0.01_radius_0_1',\n",
      "       'HpHp_0.01_magnitude_0_1', 'HpHp_0.01_covariance_0_1',\n",
      "       'HpHp_0.01_pcc_0_1', 'label'],\n",
      "      dtype='object', length=101)\n",
      "    MI_dir_5_weight  MI_dir_5_mean  MI_dir_5_std  MI_dir_3_weight  \\\n",
      "0          1.000000      74.000000  0.000000e+00         1.000000   \n",
      "1          1.000000      66.000000  0.000000e+00         1.000000   \n",
      "2          1.526832      64.830688  4.429408e+01         1.680775   \n",
      "3          2.526176     622.657698  4.749285e+05         2.680341   \n",
      "4          3.525404     864.145569  4.874849e+05         3.679850   \n",
      "5          4.524294     926.222528  3.933177e+05         4.679155   \n",
      "6          1.521825      62.057367  8.111442e+00         1.676885   \n",
      "7          1.246144    1195.106922  3.160013e+05         1.562080   \n",
      "8          2.245768    1319.292982  1.945041e+05         2.561797   \n",
      "9          3.245069    1265.582874  1.410422e+05         3.561318   \n",
      "10         1.382101     299.479400  2.588303e+05         2.062048   \n",
      "11         2.381512     198.921696  1.641168e+05         3.061520   \n",
      "12         3.381512     157.838983  1.196027e+05         4.061520   \n",
      "13         1.000000      60.000054  7.157109e-02         1.000069   \n",
      "14         1.000000      60.000005  6.045021e-03         1.000078   \n",
      "15         1.000000      60.000000  1.142780e-09         1.000021   \n",
      "16         1.000000      60.000000  9.640644e-11         1.000021   \n",
      "17         1.000000      60.000000  0.000000e+00         1.000021   \n",
      "18         1.000000      60.000000  0.000000e+00         1.000021   \n",
      "19         1.000000      60.000000  4.547474e-13         1.000021   \n",
      "\n",
      "    MI_dir_3_mean  MI_dir_3_std  MI_dir_1_weight  MI_dir_1_mean  \\\n",
      "0       74.000000  0.000000e+00         1.000000      74.000000   \n",
      "1       66.000000  0.000000e+00         1.000000      66.000000   \n",
      "2       65.670507  4.723245e+01         1.879700      66.552002   \n",
      "3      591.099667  4.639312e+05         2.879538     555.327601   \n",
      "4      831.028035  4.921250e+05         3.879362     792.137771   \n",
      "5      898.128182  4.035162e+05         4.879118     864.458678   \n",
      "6       62.421938  8.665844e+00         1.878021      62.805148   \n",
      "7      966.075063  4.589911e+05         2.304564     675.153078   \n",
      "8     1164.344074  3.412186e+05         3.304425     916.903755   \n",
      "9     1158.912357  2.454817e+05         4.304219     969.897399   \n",
      "10     491.673878  3.832848e+05         3.976233     662.141868   \n",
      "11     350.674036  2.990755e+05         4.975893     541.130059   \n",
      "12     279.106245  2.411201e+05         5.975893     460.618239   \n",
      "13      60.075350  9.962926e+01         1.115365     154.112902   \n",
      "14      60.017139  2.261535e+01         1.160186     115.313040   \n",
      "15      60.000002  2.090809e-03         1.030764      62.808887   \n",
      "16      60.000000  4.746363e-04         1.032001      61.715209   \n",
      "17      60.000000  4.366120e-08         1.028385      60.077529   \n",
      "18      60.000000  9.909854e-09         1.028417      60.047395   \n",
      "19      60.000000  4.547474e-13         1.028172      60.002124   \n",
      "\n",
      "     MI_dir_1_std  MI_dir_0.1_weight  MI_dir_0.1_mean  MI_dir_0.1_std  \\\n",
      "0        0.000000           1.000000        74.000000        0.000000   \n",
      "1        0.000000           1.000000        66.000000        0.000000   \n",
      "2       48.799298           1.987264        66.955139       48.997988   \n",
      "3   449056.504761           2.987247       537.972348   440917.727394   \n",
      "4   494773.171588           3.987229       772.728781   494963.162530   \n",
      "5   413655.898608           4.987204       847.374059   417932.906735   \n",
      "6        8.962033           1.987076        62.980488        8.999619   \n",
      "7   489177.332296           2.915980       546.872570   448635.535992   \n",
      "8   475818.664690           3.915962       783.628543   497519.251251   \n",
      "9   374550.948049           4.915938       857.138720   417474.624973   \n",
      "10  431447.200261           5.746677       710.360257   434315.224511   \n",
      "11  402962.135313           6.746628       613.962433   423340.842221   \n",
      "12  367785.360441           7.746628       542.452295   403192.669892   \n",
      "13  115516.561938           4.423137       676.918511   434271.527950   \n",
      "14   69879.711269           6.394297       467.001891   370846.084667   \n",
      "15    3704.161248           4.088824       526.039304   398377.770304   \n",
      "16    2258.840835           5.465366       392.532604   327755.705212   \n",
      "17     102.451487           3.854901       405.144026   336760.856964   \n",
      "18      62.495522           4.816010       323.485280   277893.213303   \n",
      "19       2.807382           3.690172       311.613425   269035.566687   \n",
      "\n",
      "    MI_dir_0.01_weight  MI_dir_0.01_mean  MI_dir_0.01_std  HH_5_weight_0  \\\n",
      "0             1.000000         74.000000         0.000000       1.000000   \n",
      "1             1.000000         66.000000         0.000000       1.000000   \n",
      "2             1.998719         66.995514        48.999980       1.526832   \n",
      "3             2.998717        536.197616    440051.509404       2.526176   \n",
      "4             3.998716        770.723522    494939.847143       3.525404   \n",
      "5             4.998713        845.598091    418343.980425       4.524294   \n",
      "6             1.998700         62.998049         8.999996       1.521825   \n",
      "7             2.991431        534.679313    443065.960733       1.246144   \n",
      "8             3.991429        770.013737    497733.822601       2.245768   \n",
      "9             4.991427        845.139805    420543.393457       3.245069   \n",
      "10            5.974065        714.096661    434331.939581       1.382101   \n",
      "11            6.974060        620.306721    424604.867457       2.381512   \n",
      "12            7.974060        550.040542    405789.877468       3.381512   \n",
      "13            5.814004        710.096943    436001.516047       1.000000   \n",
      "14            8.690626        493.653290    383549.572056       1.000000   \n",
      "15            6.608951        611.730810    424301.776677       1.000000   \n",
      "16            9.384120        447.441895    360581.609919       1.000000   \n",
      "17            7.375757        536.927535    402450.981971       1.000000   \n",
      "18           10.053002        408.901973    338160.209904       1.000000   \n",
      "19            8.115138        478.157426    377433.514915       1.000000   \n",
      "\n",
      "    HH_5_mean_0    HH_5_std_0  HH_5_radius_0_1  HH_5_magnitude_0_1  \\\n",
      "0     74.000000  0.000000e+00     0.000000e+00           74.000000   \n",
      "1     66.000000  0.000000e+00     0.000000e+00           99.156442   \n",
      "2     64.830688  4.429408e+01     6.655380e+00           92.514961   \n",
      "3    622.657698  4.749285e+05     6.891506e+02          626.145837   \n",
      "4    864.145569  4.874849e+05     6.982012e+02          866.662312   \n",
      "5    926.222528  3.933177e+05     6.271504e+02          928.571037   \n",
      "6     62.057367  8.111442e+00     6.271569e+02          928.299137   \n",
      "7   1195.106922  3.160013e+05     8.422107e+02         1512.008177   \n",
      "8   1319.292982  1.945041e+05     7.666953e+02         1611.962203   \n",
      "9   1265.582874  1.410422e+05     7.309992e+02         1568.307425   \n",
      "10   299.479400  2.588303e+05     6.323547e+02         1300.533706   \n",
      "11   198.921696  1.641168e+05     5.524120e+02         1281.120545   \n",
      "12   157.838983  1.196027e+05     5.105340e+02         1275.387453   \n",
      "13    60.000054  7.157109e-02     3.458363e+02          168.858375   \n",
      "14    60.000005  6.045021e-03     2.785967e-01           84.852855   \n",
      "15    60.000000  1.142780e-09     7.774974e-02           84.852817   \n",
      "16    60.000000  9.640644e-11     3.520208e-05           84.852814   \n",
      "17    60.000000  0.000000e+00     9.818678e-06           84.852814   \n",
      "18    60.000000  0.000000e+00     0.000000e+00           84.852814   \n",
      "19    60.000000  4.547474e-13     6.743496e-07           84.852814   \n",
      "\n",
      "    HH_5_covariance_0_1  HH_5_pcc_0_1  HH_3_weight_0  HH_3_mean_0  \\\n",
      "0          0.000000e+00      0.000000       1.000000    74.000000   \n",
      "1          0.000000e+00      0.000000       1.000000    66.000000   \n",
      "2          0.000000e+00      0.000000       1.680775    65.670507   \n",
      "3          0.000000e+00      0.000000       2.680341   591.099667   \n",
      "4          0.000000e+00      0.000000       3.679850   831.028035   \n",
      "5          0.000000e+00      0.000000       4.679155   898.128182   \n",
      "6         -1.200100e+02     -0.067189       1.676885    62.421938   \n",
      "7          3.793212e+04      0.107595       1.562080   966.075063   \n",
      "8          3.636440e+04      0.131474       2.561797  1164.344074   \n",
      "9          1.896094e+04      0.080503       3.561318  1158.912357   \n",
      "10         2.111593e+04      0.110517       2.062048   491.673878   \n",
      "11         2.033651e+04      0.133667       3.061520   350.674036   \n",
      "12         1.904266e+04      0.146616       4.061520   279.106245   \n",
      "13         7.035502e-03      0.000076       1.000069    60.075350   \n",
      "14         3.515984e-03      0.169036       1.000078    60.017139   \n",
      "15         1.123135e-10      0.000043       1.000021    60.000002   \n",
      "16         5.613338e-11      0.169117       1.000021    60.000000   \n",
      "17         1.778536e-18      0.000000       1.000021    60.000000   \n",
      "18         8.887779e-19      0.000000       1.000021    60.000000   \n",
      "19         2.744143e-26      0.000000       1.000021    60.000000   \n",
      "\n",
      "      HH_3_std_0  HH_3_radius_0_1  HH_3_magnitude_0_1  HH_3_covariance_0_1  \\\n",
      "0   0.000000e+00         0.000000           74.000000         0.000000e+00   \n",
      "1   0.000000e+00         0.000000           99.156442         0.000000e+00   \n",
      "2   4.723245e+01         6.872587           93.105400         0.000000e+00   \n",
      "3   4.639312e+05       681.124945          594.772912         0.000000e+00   \n",
      "4   4.921250e+05       701.516213          833.644766         0.000000e+00   \n",
      "5   4.035162e+05       635.229267          900.549960         0.000000e+00   \n",
      "6   8.665844e+00       635.236088          900.294801        -1.294743e+02   \n",
      "7   4.589911e+05       928.712709         1319.066056         4.913518e+04   \n",
      "8   3.412186e+05       862.980209         1470.486775         5.683371e+04   \n",
      "9   2.454817e+05       805.604095         1466.189647         4.357857e+04   \n",
      "10  3.832848e+05       792.947997         1258.896760         3.680119e+04   \n",
      "11  2.990755e+05       737.941226         1210.805571         3.179433e+04   \n",
      "12  2.411201e+05       697.568531         1192.047879         2.798310e+04   \n",
      "13  9.962926e+01       491.141271          285.498413         2.057420e+01   \n",
      "14  2.261535e+01        11.056428           84.918223         1.028539e+01   \n",
      "15  2.090809e-03         4.755780           84.864935         4.318216e-04   \n",
      "16  4.746363e-04         0.050650           84.852815         2.158615e-04   \n",
      "17  4.366120e-08         0.021787           84.852814         9.017433e-09   \n",
      "18  9.909854e-09         0.000231           84.852814         4.507320e-09   \n",
      "19  4.547474e-13         0.000100           84.852814         1.853914e-13   \n",
      "\n",
      "    HH_3_pcc_0_1  HH_1_weight_0  HH_1_mean_0     HH_1_std_0  HH_1_radius_0_1  \\\n",
      "0       0.000000       1.000000    74.000000       0.000000         0.000000   \n",
      "1       0.000000       1.000000    66.000000       0.000000         0.000000   \n",
      "2       0.000000       1.879700    66.552002      48.799298         6.985649   \n",
      "3       0.000000       2.879538   555.327601  449056.504761       670.116784   \n",
      "4       0.000000       3.879362   792.137771  494773.171588       703.401146   \n",
      "5       0.000000       4.879118   864.458678  413655.898608       643.160865   \n",
      "6      -0.069239       1.878021    62.805148       8.962033       643.167832   \n",
      "7       0.114172       2.304564   675.153078  489177.332296       950.175368   \n",
      "8       0.153165       3.304425   916.903755  475818.664690       943.119591   \n",
      "9       0.138463       4.304219   969.897399  374550.948049       887.810141   \n",
      "10      0.119975       3.976233   662.141868  431447.200261       897.773996   \n",
      "11      0.117341       4.975893   541.130059  402962.135313       881.767023   \n",
      "12      0.115019       5.975893   460.618239  367785.360441       861.589408   \n",
      "13      0.004198       1.115365   154.112902  115516.561938       695.199196   \n",
      "14      0.216683       1.160186   115.313040   69879.711269       430.576675   \n",
      "15      0.001986       1.030764    62.808887    3704.161248       271.263474   \n",
      "16      0.216689       1.032001    61.715209    2258.840835        77.220477   \n",
      "17      0.001981       1.028385    60.077529     102.451487        48.593130   \n",
      "18      0.216689       1.028417    60.047395      62.495522        12.843170   \n",
      "19      0.002762       1.028172    60.002124       2.807382         8.081021   \n",
      "\n",
      "    HH_1_magnitude_0_1  HH_1_covariance_0_1  HH_1_pcc_0_1  HH_0.1_weight_0  \\\n",
      "0            74.000000             0.000000      0.000000         1.000000   \n",
      "1            99.156442             0.000000      0.000000         1.000000   \n",
      "2            93.729232             0.000000      0.000000         1.987264   \n",
      "3           559.235858             0.000000      0.000000         2.987247   \n",
      "4           794.882537             0.000000      0.000000         3.987229   \n",
      "5           866.974513             0.000000      0.000000         4.987204   \n",
      "6           866.737153          -136.206859     -0.070742         1.987076   \n",
      "7          1096.868490         44592.579388      0.099131         2.915980   \n",
      "8          1260.159237         63167.848685      0.142382         3.915962   \n",
      "9          1299.226605         61165.171190      0.155392         4.915938   \n",
      "10         1174.364857         40369.286502      0.100423         5.746677   \n",
      "11         1110.640674         26539.311543      0.068313         6.746628   \n",
      "12         1073.717899         16880.691681      0.045482         7.746628   \n",
      "13          485.715913         33297.271273      0.161543         4.423137   \n",
      "14          192.478268         20911.951217      0.232754         6.394297   \n",
      "15          131.309000          1377.677445      0.085630         4.088824   \n",
      "16           88.055229           712.014890      0.246151         5.465366   \n",
      "17           86.128256            38.396452      0.079816         3.854901   \n",
      "18           84.941151            19.728097      0.246548         4.816010   \n",
      "19           84.887835             1.052505      0.079460         3.690172   \n",
      "\n",
      "    HH_0.1_mean_0   HH_0.1_std_0  HH_0.1_radius_0_1  HH_0.1_magnitude_0_1  \\\n",
      "0       74.000000       0.000000           0.000000             74.000000   \n",
      "1       66.000000       0.000000           0.000000             99.156442   \n",
      "2       66.955139      48.997988           6.999856             94.015907   \n",
      "3      537.972348  440917.727394         664.016361            542.005763   \n",
      "4      772.728781  494963.162530         703.536184            775.542242   \n",
      "5      847.374059  417932.906735         646.477306            849.940466   \n",
      "6       62.980488       8.999619         646.484266            849.711326   \n",
      "7      546.872570  448635.535992         930.896580           1008.519907   \n",
      "8      783.628543  497519.251251         956.792641           1154.173509   \n",
      "9      857.138720  417474.624973         914.006308           1205.292322   \n",
      "10     710.360257  434315.224511         922.924617           1113.237836   \n",
      "11     613.962433  423340.842221         916.959905           1054.341811   \n",
      "12     542.452295  403192.669892         905.906891           1014.367427   \n",
      "13     676.918511  434271.527950         915.130700            867.452110   \n",
      "14     467.001891  370846.084667         897.283463            822.380348   \n",
      "15     526.039304  398377.770304         877.054078            703.425984   \n",
      "16     392.532604  327755.705212         852.134658            656.352950   \n",
      "17     405.144026  336760.856964         815.178853            564.113045   \n",
      "18     323.485280  277893.213303         783.998769            518.444219   \n",
      "19     311.613425  269035.566687         739.546334            449.161055   \n",
      "\n",
      "    HH_0.1_covariance_0_1  HH_0.1_pcc_0_1  HH_0.01_weight_0  HH_0.01_mean_0  \\\n",
      "0                0.000000        0.000000          1.000000       74.000000   \n",
      "1                0.000000        0.000000          1.000000       66.000000   \n",
      "2                0.000000        0.000000          1.998719       66.995514   \n",
      "3                0.000000        0.000000          2.998717      536.197616   \n",
      "4                0.000000        0.000000          3.998716      770.723522   \n",
      "5                0.000000        0.000000          4.998713      845.598091   \n",
      "6             -138.112994       -0.071215          1.998700       62.998049   \n",
      "7            38243.070847        0.088319          2.991431      534.679313   \n",
      "8            58654.467389        0.128630          3.991429      770.013737   \n",
      "9            61593.751423        0.147458          4.991427      845.139805   \n",
      "10           37183.398211        0.087324          5.974065      714.096661   \n",
      "11           19613.969351        0.046656          6.974060      620.306721   \n",
      "12            6614.838878        0.016123          7.974060      550.040542   \n",
      "13           37279.436998        0.089091          5.814004      710.096943   \n",
      "14           57661.091588        0.143683          8.690626      493.653290   \n",
      "15           73517.559159        0.191270          6.608951      611.730810   \n",
      "16           82252.135255        0.227627          9.384120      447.441895   \n",
      "17           86581.444452        0.260609          7.375757      536.927535   \n",
      "18           87093.577726        0.284699         10.053002      408.901973   \n",
      "19           84096.791325        0.307564          8.115138      478.157426   \n",
      "\n",
      "    HH_0.01_std_0  HH_0.01_radius_0_1  HH_0.01_magnitude_0_1  \\\n",
      "0        0.000000            0.000000              74.000000   \n",
      "1        0.000000            0.000000              99.156442   \n",
      "2       48.999980            6.999999              94.044664   \n",
      "3   440051.509404          663.363784             540.244281   \n",
      "4   494939.847143          703.519614             773.544277   \n",
      "5   418343.980425          646.795161             848.169871   \n",
      "6        8.999996          646.802118             847.941558   \n",
      "7   443065.960733          928.121728            1000.458944   \n",
      "8   497733.822601          957.119534            1143.659602   \n",
      "9   420543.393457          915.907951            1195.532275   \n",
      "10  434331.939581          924.594686            1106.433609   \n",
      "11  424604.867457          919.319455            1048.351906   \n",
      "12  405789.877468          909.028751            1008.367933   \n",
      "13  436001.516047          917.491904             898.210592   \n",
      "14  383549.572056          905.290610             864.830180   \n",
      "15  424301.776677          898.805512             786.071342   \n",
      "16  360581.609919          885.936446             757.904238   \n",
      "17  402450.981971          873.517368             698.924479   \n",
      "18  338160.209904          860.587701             674.901475   \n",
      "19  377433.514915          845.927730             629.154470   \n",
      "\n",
      "    HH_0.01_covariance_0_1  HH_0.01_pcc_0_1  HH_jit_5_weight  HH_jit_5_mean  \\\n",
      "0                 0.000000         0.000000         1.000000       0.000000   \n",
      "1                 0.000000         0.000000         1.000000       0.000000   \n",
      "2                 0.000000         0.000000         1.526832       0.121112   \n",
      "3                 0.000000         0.000000         2.526176       0.073218   \n",
      "4                 0.000000         0.000000         3.525404       0.052474   \n",
      "5                 0.000000         0.000000         4.524294       0.040896   \n",
      "6              -138.260974        -0.071254         1.521825       0.123320   \n",
      "7             37535.748880         0.087185         1.246144       0.446177   \n",
      "8             57992.361727         0.127088         2.245768       0.247541   \n",
      "9             61349.387709         0.146264         3.245069       0.171287   \n",
      "10            36753.232371         0.085996         1.382101       0.527284   \n",
      "11            18898.625507         0.044723         2.381512       0.305928   \n",
      "12             5597.806022         0.013551         3.381512       0.215457   \n",
      "13            29625.918669         0.070433         1.000000       5.221475   \n",
      "14            47614.070528         0.116434         1.000000       5.221335   \n",
      "15            60803.051098         0.150722         1.000000       5.180124   \n",
      "16            70651.950504         0.180628         1.000000       5.180074   \n",
      "17            77792.754874         0.204212         1.000000       5.182453   \n",
      "18            83010.304351         0.225016         1.000000       5.182531   \n",
      "19            86628.022651         0.242481         1.000000       5.189952   \n",
      "\n",
      "    HH_jit_5_std  HH_jit_3_weight  HH_jit_3_mean  HH_jit_3_std  \\\n",
      "0   0.000000e+00         1.000000       0.000000  0.000000e+00   \n",
      "1   0.000000e+00         1.000000       0.000000  0.000000e+00   \n",
      "2   7.727575e-03         1.680775       0.110019  8.240204e-03   \n",
      "3   8.169305e-03         2.680341       0.069019  7.990594e-03   \n",
      "4   6.938717e-03         3.679850       0.050287  6.759458e-03   \n",
      "5   5.877513e-03         4.679155       0.039559  5.738267e-03   \n",
      "6   7.935882e-03         1.676885       0.111917  8.478285e-03   \n",
      "7   2.722464e-02         1.562080       0.376775  4.248039e-02   \n",
      "8   6.425523e-02         2.561797       0.229734  5.966558e-02   \n",
      "9   5.750887e-02         3.561318       0.165251  5.356190e-02   \n",
      "10  9.201977e-02         2.062048       0.366212  1.162782e-01   \n",
      "11  1.210722e-01         3.061520       0.246635  1.077749e-01   \n",
      "12  1.047607e-01         4.061520       0.185910  9.252863e-02   \n",
      "13  1.147398e-06         1.000069       5.221128  1.756511e-03   \n",
      "14  1.177582e-06         1.000078       5.220941  1.990397e-03   \n",
      "15  2.730971e-11         1.000021       5.180125  7.214235e-08   \n",
      "16  2.720668e-11         1.000021       5.180075  7.682279e-08   \n",
      "17  9.237056e-14         1.000021       5.182453  1.147313e-10   \n",
      "18  9.947598e-14         1.000021       5.182531  1.275673e-10   \n",
      "19  8.739676e-13         1.000021       5.189952  1.156057e-09   \n",
      "\n",
      "    HH_jit_1_weight  HH_jit_1_mean  HH_jit_1_std  HH_jit_0.1_weight  \\\n",
      "0          1.000000       0.000000      0.000000           1.000000   \n",
      "1          1.000000       0.000000      0.000000           1.000000   \n",
      "2          1.879700       0.098376      0.008514           1.987264   \n",
      "3          2.879538       0.064255      0.007745           2.987247   \n",
      "4          3.879362       0.047715      0.006536           3.987229   \n",
      "5          4.879118       0.037954      0.005566           4.987204   \n",
      "6          1.878021       0.099931      0.008768           1.987076   \n",
      "7          2.304564       0.284658      0.049480           2.915980   \n",
      "8          3.304425       0.198540      0.051597           3.915962   \n",
      "9          4.304219       0.152434      0.046633           4.915938   \n",
      "10         3.976233       0.207758      0.089981           5.746677   \n",
      "11         4.975893       0.166029      0.078821           6.746628   \n",
      "12         5.975893       0.138246      0.069472           7.746628   \n",
      "13         1.115365       4.697172      2.387644           4.423137   \n",
      "14         1.160186       4.519517      3.084446           6.394297   \n",
      "15         1.030764       5.165710      0.078015           4.088824   \n",
      "16         1.032001       5.159591      0.108757           5.465366   \n",
      "17         1.028385       5.181991      0.002161           3.854901   \n",
      "18         1.028417       5.181897      0.003019           4.816010   \n",
      "19         1.028172       5.189734      0.000061           3.690172   \n",
      "\n",
      "    HH_jit_0.1_mean  HH_jit_0.1_std  HH_jit_0.01_weight  HH_jit_0.01_mean  \\\n",
      "0          0.000000        0.000000            1.000000          0.000000   \n",
      "1          0.000000        0.000000            1.000000          0.000000   \n",
      "2          0.093051        0.008548            1.998719          0.092518   \n",
      "3          0.061943        0.007610            2.998717          0.061707   \n",
      "4          0.046430        0.006420            3.998716          0.046297   \n",
      "5          0.037138        0.005477            4.998713          0.037053   \n",
      "6          0.094446        0.008805            1.998700          0.093897   \n",
      "7          0.242321        0.047682            2.991431          0.238226   \n",
      "8          0.180463        0.046663            3.991429          0.178563   \n",
      "9          0.143771        0.042443            4.991427          0.142807   \n",
      "10         0.154771        0.070205            5.974065          0.150223   \n",
      "11         0.131848        0.062819            6.974060          0.128700   \n",
      "12         0.114828        0.056664            7.974060          0.112560   \n",
      "13         1.291758        4.544111            5.814004          1.016330   \n",
      "14         0.913432        3.488108            8.690626          0.700409   \n",
      "15         2.242732        6.226145            6.608951          1.646354   \n",
      "16         1.694101        5.571280            9.384120          1.177776   \n",
      "17         3.005326        6.271283            7.375757          2.125776   \n",
      "18         2.418441        6.416597           10.053002          1.576140   \n",
      "19         3.597338        5.514674            8.115138          2.503363   \n",
      "\n",
      "    HH_jit_0.01_std  HpHp_5_weight_0  HpHp_5_mean_0  HpHp_5_std_0  \\\n",
      "0          0.000000         1.000000      74.000000  0.000000e+00   \n",
      "1          0.000000         1.000000      66.000000  0.000000e+00   \n",
      "2          0.008549         1.526832      64.830688  4.429408e+01   \n",
      "3          0.007595         2.526176     622.657698  4.749285e+05   \n",
      "4          0.006408         3.525404     864.145569  4.874849e+05   \n",
      "5          0.005468         4.524294     926.222528  3.933177e+05   \n",
      "6          0.008805         1.521825      62.057367  8.111442e+00   \n",
      "7          0.047345         1.246144    1195.106922  3.160013e+05   \n",
      "8          0.046131         2.245768    1319.292982  1.945041e+05   \n",
      "9          0.041992         3.245069    1265.582874  1.410422e+05   \n",
      "10         0.068257         1.382101     299.479400  2.588303e+05   \n",
      "11         0.061237         2.381512     198.921696  1.641168e+05   \n",
      "12         0.055374         3.381512     157.838983  1.196027e+05   \n",
      "13         3.708061         1.000000      60.000054  7.157109e-02   \n",
      "14         2.706623         1.000000      60.000005  6.045021e-03   \n",
      "15         5.373352         1.000000      60.000000  1.142780e-09   \n",
      "16         4.328761         1.000000      60.000000  9.640644e-11   \n",
      "17         6.110275         1.000000      60.000000  0.000000e+00   \n",
      "18         5.334824         1.000000      60.000000  0.000000e+00   \n",
      "19         6.371750         1.000000      60.000000  4.547474e-13   \n",
      "\n",
      "    HpHp_5_radius_0_1  HpHp_5_magnitude_0_1  HpHp_5_covariance_0_1  \\\n",
      "0        0.000000e+00             74.000000           0.000000e+00   \n",
      "1        0.000000e+00             99.156442           0.000000e+00   \n",
      "2        6.655380e+00             92.514961           0.000000e+00   \n",
      "3        6.891506e+02            626.145837           0.000000e+00   \n",
      "4        6.982012e+02            866.662312           0.000000e+00   \n",
      "5        6.271504e+02            928.571037           0.000000e+00   \n",
      "6        6.271569e+02            928.299137          -1.200100e+02   \n",
      "7        8.422107e+02           1512.008177           3.793212e+04   \n",
      "8        7.666953e+02           1611.962203           3.636440e+04   \n",
      "9        7.309992e+02           1568.307425           1.896094e+04   \n",
      "10       6.323547e+02           1300.533706           2.111593e+04   \n",
      "11       5.524120e+02           1281.120545           2.033651e+04   \n",
      "12       5.105340e+02           1275.387453           1.904266e+04   \n",
      "13       3.458363e+02            168.858375           7.035502e-03   \n",
      "14       2.785967e-01             84.852855           3.515984e-03   \n",
      "15       7.774974e-02             84.852817           1.123135e-10   \n",
      "16       3.520208e-05             84.852814           5.613338e-11   \n",
      "17       9.818678e-06             84.852814           1.778536e-18   \n",
      "18       0.000000e+00             84.852814           8.887779e-19   \n",
      "19       6.743496e-07             84.852814           2.744143e-26   \n",
      "\n",
      "    HpHp_5_pcc_0_1  HpHp_3_weight_0  HpHp_3_mean_0  HpHp_3_std_0  \\\n",
      "0         0.000000         1.000000      74.000000  0.000000e+00   \n",
      "1         0.000000         1.000000      66.000000  0.000000e+00   \n",
      "2         0.000000         1.680775      65.670507  4.723245e+01   \n",
      "3         0.000000         2.680341     591.099667  4.639312e+05   \n",
      "4         0.000000         3.679850     831.028035  4.921250e+05   \n",
      "5         0.000000         4.679155     898.128182  4.035162e+05   \n",
      "6        -0.067189         1.676885      62.421938  8.665844e+00   \n",
      "7         0.107595         1.562080     966.075063  4.589911e+05   \n",
      "8         0.131474         2.561797    1164.344074  3.412186e+05   \n",
      "9         0.080503         3.561318    1158.912357  2.454817e+05   \n",
      "10        0.110517         2.062048     491.673878  3.832848e+05   \n",
      "11        0.133667         3.061520     350.674036  2.990755e+05   \n",
      "12        0.146616         4.061520     279.106245  2.411201e+05   \n",
      "13        0.000076         1.000069      60.075350  9.962926e+01   \n",
      "14        0.169036         1.000078      60.017139  2.261535e+01   \n",
      "15        0.000043         1.000021      60.000002  2.090809e-03   \n",
      "16        0.169117         1.000021      60.000000  4.746363e-04   \n",
      "17        0.000000         1.000021      60.000000  4.366120e-08   \n",
      "18        0.000000         1.000021      60.000000  9.909854e-09   \n",
      "19        0.000000         1.000021      60.000000  4.547474e-13   \n",
      "\n",
      "    HpHp_3_radius_0_1  HpHp_3_magnitude_0_1  HpHp_3_covariance_0_1  \\\n",
      "0            0.000000             74.000000           0.000000e+00   \n",
      "1            0.000000             99.156442           0.000000e+00   \n",
      "2            6.872587             93.105400           0.000000e+00   \n",
      "3          681.124945            594.772912           0.000000e+00   \n",
      "4          701.516213            833.644766           0.000000e+00   \n",
      "5          635.229267            900.549960           0.000000e+00   \n",
      "6          635.236088            900.294801          -1.294743e+02   \n",
      "7          928.712709           1319.066056           4.913518e+04   \n",
      "8          862.980209           1470.486775           5.683371e+04   \n",
      "9          805.604095           1466.189647           4.357857e+04   \n",
      "10         792.947997           1258.896760           3.680119e+04   \n",
      "11         737.941226           1210.805571           3.179433e+04   \n",
      "12         697.568531           1192.047879           2.798310e+04   \n",
      "13         491.141271            285.498413           2.057420e+01   \n",
      "14          11.056428             84.918223           1.028539e+01   \n",
      "15           4.755780             84.864935           4.318216e-04   \n",
      "16           0.050650             84.852815           2.158615e-04   \n",
      "17           0.021787             84.852814           9.017433e-09   \n",
      "18           0.000231             84.852814           4.507320e-09   \n",
      "19           0.000100             84.852814           1.853914e-13   \n",
      "\n",
      "    HpHp_3_pcc_0_1  HpHp_1_weight_0  HpHp_1_mean_0   HpHp_1_std_0  \\\n",
      "0         0.000000         1.000000      74.000000       0.000000   \n",
      "1         0.000000         1.000000      66.000000       0.000000   \n",
      "2         0.000000         1.879700      66.552002      48.799298   \n",
      "3         0.000000         2.879538     555.327601  449056.504761   \n",
      "4         0.000000         3.879362     792.137771  494773.171588   \n",
      "5         0.000000         4.879118     864.458678  413655.898608   \n",
      "6        -0.069239         1.878021      62.805148       8.962033   \n",
      "7         0.114172         2.304564     675.153078  489177.332296   \n",
      "8         0.153165         3.304425     916.903755  475818.664690   \n",
      "9         0.138463         4.304219     969.897399  374550.948049   \n",
      "10        0.119975         3.976233     662.141868  431447.200261   \n",
      "11        0.117341         4.975893     541.130059  402962.135313   \n",
      "12        0.115019         5.975893     460.618239  367785.360441   \n",
      "13        0.004198         1.115365     154.112902  115516.561938   \n",
      "14        0.216683         1.160186     115.313040   69879.711269   \n",
      "15        0.001986         1.030764      62.808887    3704.161248   \n",
      "16        0.216689         1.032001      61.715209    2258.840835   \n",
      "17        0.001981         1.028385      60.077529     102.451487   \n",
      "18        0.216689         1.028417      60.047395      62.495522   \n",
      "19        0.002762         1.028172      60.002124       2.807382   \n",
      "\n",
      "    HpHp_1_radius_0_1  HpHp_1_magnitude_0_1  HpHp_1_covariance_0_1  \\\n",
      "0            0.000000             74.000000               0.000000   \n",
      "1            0.000000             99.156442               0.000000   \n",
      "2            6.985649             93.729232               0.000000   \n",
      "3          670.116784            559.235858               0.000000   \n",
      "4          703.401146            794.882537               0.000000   \n",
      "5          643.160865            866.974513               0.000000   \n",
      "6          643.167832            866.737153            -136.206859   \n",
      "7          950.175368           1096.868490           44592.579388   \n",
      "8          943.119591           1260.159237           63167.848685   \n",
      "9          887.810141           1299.226605           61165.171190   \n",
      "10         897.773996           1174.364857           40369.286502   \n",
      "11         881.767023           1110.640674           26539.311543   \n",
      "12         861.589408           1073.717899           16880.691681   \n",
      "13         695.199196            485.715913           33297.271273   \n",
      "14         430.576675            192.478268           20911.951217   \n",
      "15         271.263474            131.309000            1377.677445   \n",
      "16          77.220477             88.055229             712.014890   \n",
      "17          48.593130             86.128256              38.396452   \n",
      "18          12.843170             84.941151              19.728097   \n",
      "19           8.081021             84.887835               1.052505   \n",
      "\n",
      "    HpHp_1_pcc_0_1  HpHp_0.1_weight_0  HpHp_0.1_mean_0  HpHp_0.1_std_0  \\\n",
      "0         0.000000           1.000000        74.000000        0.000000   \n",
      "1         0.000000           1.000000        66.000000        0.000000   \n",
      "2         0.000000           1.987264        66.955139       48.997988   \n",
      "3         0.000000           2.987247       537.972348   440917.727394   \n",
      "4         0.000000           3.987229       772.728781   494963.162530   \n",
      "5         0.000000           4.987204       847.374059   417932.906735   \n",
      "6        -0.070742           1.987076        62.980488        8.999619   \n",
      "7         0.099131           2.915980       546.872570   448635.535992   \n",
      "8         0.142382           3.915962       783.628543   497519.251251   \n",
      "9         0.155392           4.915938       857.138720   417474.624973   \n",
      "10        0.100423           5.746677       710.360257   434315.224511   \n",
      "11        0.068313           6.746628       613.962433   423340.842221   \n",
      "12        0.045482           7.746628       542.452295   403192.669892   \n",
      "13        0.161543           4.423137       676.918511   434271.527950   \n",
      "14        0.232754           6.394297       467.001891   370846.084667   \n",
      "15        0.085630           4.088824       526.039304   398377.770304   \n",
      "16        0.246151           5.465366       392.532604   327755.705212   \n",
      "17        0.079816           3.854901       405.144026   336760.856964   \n",
      "18        0.246548           4.816010       323.485280   277893.213303   \n",
      "19        0.079460           3.690172       311.613425   269035.566687   \n",
      "\n",
      "    HpHp_0.1_radius_0_1  HpHp_0.1_magnitude_0_1  HpHp_0.1_covariance_0_1  \\\n",
      "0              0.000000               74.000000                 0.000000   \n",
      "1              0.000000               99.156442                 0.000000   \n",
      "2              6.999856               94.015907                 0.000000   \n",
      "3            664.016361              542.005763                 0.000000   \n",
      "4            703.536184              775.542242                 0.000000   \n",
      "5            646.477306              849.940466                 0.000000   \n",
      "6            646.484266              849.711326              -138.112994   \n",
      "7            930.896580             1008.519907             38243.070847   \n",
      "8            956.792641             1154.173509             58654.467389   \n",
      "9            914.006308             1205.292322             61593.751423   \n",
      "10           922.924617             1113.237836             37183.398211   \n",
      "11           916.959905             1054.341811             19613.969351   \n",
      "12           905.906891             1014.367427              6614.838878   \n",
      "13           915.130700              867.452110             37279.436998   \n",
      "14           897.283463              822.380348             57661.091588   \n",
      "15           877.054078              703.425984             73517.559159   \n",
      "16           852.134658              656.352950             82252.135255   \n",
      "17           815.178853              564.113045             86581.444452   \n",
      "18           783.998769              518.444219             87093.577726   \n",
      "19           739.546334              449.161055             84096.791325   \n",
      "\n",
      "    HpHp_0.1_pcc_0_1  HpHp_0.01_weight_0  HpHp_0.01_mean_0  HpHp_0.01_std_0  \\\n",
      "0           0.000000            1.000000         74.000000         0.000000   \n",
      "1           0.000000            1.000000         66.000000         0.000000   \n",
      "2           0.000000            1.998719         66.995514        48.999980   \n",
      "3           0.000000            2.998717        536.197616    440051.509404   \n",
      "4           0.000000            3.998716        770.723522    494939.847143   \n",
      "5           0.000000            4.998713        845.598091    418343.980425   \n",
      "6          -0.071215            1.998700         62.998049         8.999996   \n",
      "7           0.088319            2.991431        534.679313    443065.960733   \n",
      "8           0.128630            3.991429        770.013737    497733.822601   \n",
      "9           0.147458            4.991427        845.139805    420543.393457   \n",
      "10          0.087324            5.974065        714.096661    434331.939581   \n",
      "11          0.046656            6.974060        620.306721    424604.867457   \n",
      "12          0.016123            7.974060        550.040542    405789.877468   \n",
      "13          0.089091            5.814004        710.096943    436001.516047   \n",
      "14          0.143683            8.690626        493.653290    383549.572056   \n",
      "15          0.191270            6.608951        611.730810    424301.776677   \n",
      "16          0.227627            9.384120        447.441895    360581.609919   \n",
      "17          0.260609            7.375757        536.927535    402450.981971   \n",
      "18          0.284699           10.053002        408.901973    338160.209904   \n",
      "19          0.307564            8.115138        478.157426    377433.514915   \n",
      "\n",
      "    HpHp_0.01_radius_0_1  HpHp_0.01_magnitude_0_1  HpHp_0.01_covariance_0_1  \\\n",
      "0               0.000000                74.000000                  0.000000   \n",
      "1               0.000000                99.156442                  0.000000   \n",
      "2               6.999999                94.044664                  0.000000   \n",
      "3             663.363784               540.244281                  0.000000   \n",
      "4             703.519614               773.544277                  0.000000   \n",
      "5             646.795161               848.169871                  0.000000   \n",
      "6             646.802118               847.941558               -138.260974   \n",
      "7             928.121728              1000.458944              37535.748880   \n",
      "8             957.119534              1143.659602              57992.361727   \n",
      "9             915.907951              1195.532275              61349.387709   \n",
      "10            924.594686              1106.433609              36753.232371   \n",
      "11            919.319455              1048.351906              18898.625507   \n",
      "12            909.028751              1008.367933               5597.806022   \n",
      "13            917.491904               898.210592              29625.918669   \n",
      "14            905.290610               864.830180              47614.070528   \n",
      "15            898.805512               786.071342              60803.051098   \n",
      "16            885.936446               757.904238              70651.950504   \n",
      "17            873.517368               698.924479              77792.754874   \n",
      "18            860.587701               674.901475              83010.304351   \n",
      "19            845.927730               629.154470              86628.022651   \n",
      "\n",
      "    HpHp_0.01_pcc_0_1  label  \n",
      "0            0.000000      1  \n",
      "1            0.000000      1  \n",
      "2            0.000000      1  \n",
      "3            0.000000      1  \n",
      "4            0.000000      1  \n",
      "5            0.000000      1  \n",
      "6           -0.071254      1  \n",
      "7            0.087185      1  \n",
      "8            0.127088      1  \n",
      "9            0.146264      1  \n",
      "10           0.085996      1  \n",
      "11           0.044723      1  \n",
      "12           0.013551      1  \n",
      "13           0.070433      1  \n",
      "14           0.116434      1  \n",
      "15           0.150722      1  \n",
      "16           0.180628      1  \n",
      "17           0.204212      1  \n",
      "18           0.225016      1  \n",
      "19           0.242481      1  \n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "#### Thay đổi hiển thị ####\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.set_option('display.max_row', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9  # Adjust as needed\n",
    "session = InteractiveSession(config=config)\n",
    "#### Change display ####\n",
    "\n",
    "# input_file = [\"/mnt/c/Users/hoang/FileCSV_DACN_2025/parquet_shuffled_IoT23\", \"C:\\\\Users\\\\hoang\\\\FileCSV_DACN_2025\\\\parquet_shuffled_IoT23\"]\n",
    "input_file = [\"/mnt/c/Users/hoang/FileCSV_DACN_2025/medbiot.csv\", \"C:\\\\Users\\\\hoang\\\\FileCSV_DACN_2025\\\\medbiot.csv\"]\n",
    "\n",
    "\n",
    "if os.name == 'nt':\n",
    "    input_file = input_file[1]\n",
    "else:\n",
    "    input_file = input_file[0]\n",
    "\n",
    "# dictTypes = {}\n",
    "# df = dd.read_parquet(input_file)\n",
    "# for col in df.columns:\n",
    "#     if col.startswith('proto') == True:\n",
    "#         dictTypes[col] = 'int32'\n",
    "#     elif col.startswith('service_') == True:\n",
    "#         dictTypes[col] = 'int32'\n",
    "#     # elif col == 'label':\n",
    "#     #     dictTypes[col]= 'int32'\n",
    "#     elif col.startswith('detailed-label'):\n",
    "#         dictTypes[col] = 'str'\n",
    "#     else:\n",
    "#         dictTypes[col]='float32'\n",
    "\n",
    "df = dd.read_csv(input_file) # dtype = dictTypes\n",
    "\n",
    "label_map = {'benign': 0, 'torii': 1, 'mirai_spread': 2, 'bashlite_spread': 3, 'mirai_c2': 4, 'bashlite_c2': 5}\n",
    "df['label'] = df['label'].map(label_map).astype('int32')\n",
    "# phân loại đa nhãn, k dùng\n",
    "# df = df.replace(r'[N|n][a|A][N|n]', 0)\n",
    "# df = df.replace(np.nan, 0)\n",
    "print(df.columns)\n",
    "# print(df['duration'].value_counts().compute())\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c557b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow import keras\n",
    "\n",
    "#Global var \n",
    "batch_size = 512\n",
    "ratio_test_all = 0.2\n",
    "\n",
    "from dask_ml.model_selection import train_test_split \n",
    "# Bước 1: Tách 80% train, 20% còn lại (val + test)\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.20, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.75, random_state=42, shuffle=True)\n",
    "def val_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Len:  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.083984375\n",
      "57.119140625\n",
      "56.77734375\n",
      "57.6953125\n"
     ]
    }
   ],
   "source": [
    "features_len = len(df.columns)-1\n",
    "print(\"Feature Len: \",features_len)\n",
    "batchSize = 512\n",
    "def dask_to_tf_dataset(dask_df, num_classes):\n",
    "    def generator():\n",
    "        # for partition in dask_df.partitions:\n",
    "        #     batch = partition.compute() \n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch=batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "            \n",
    "            X = batch.drop(columns='label').values.astype(np.float32)\n",
    "            y = batch['label'].values.astype(np.int32)\n",
    "            y_onehot = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "            num_splits = max(1, len(X)//batchSize) # Đảm bảo không chia nhỏ quá mức\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y_onehot, num_splits) # y_onehot\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, features_len), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None, num_classes), dtype=tf.int32), # 3\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e384ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = dask_to_tf_dataset(train_df,  6).repeat()\n",
    "val_gen = dask_to_tf_dataset(val_df, 6).repeat()\n",
    "test_gen = dask_to_tf_dataset(test_df, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f49182cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps/Epoch:  18825\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "batchSize=512\n",
    "n_samples = np.ceil(train_df.shape[0])\n",
    "steps_per_epoch = int(n_samples / (batchSize))\n",
    "validation_steps =int (steps_per_epoch/ 16)\n",
    "print(\"Steps/Epoch: \", steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (100, 1) \n",
      " Output Shape: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m819,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m774\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">821,638</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m821,638\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">821,126</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m821,126\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Path:  Centralized_Model/cnn_model_Month05Day26__10h08p\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254102.151827   87575 buffer_comparator.cc:156] Difference at 0: 0.0853882, expected -nan\n",
      "E0000 00:00:1748254102.151925   87575 buffer_comparator.cc:156] Difference at 2: 0.0135651, expected -nan\n",
      "E0000 00:00:1748254102.151937   87575 buffer_comparator.cc:156] Difference at 4: 0.0411987, expected -nan\n",
      "E0000 00:00:1748254102.151941   87575 buffer_comparator.cc:156] Difference at 6: 0.0252533, expected -nan\n",
      "E0000 00:00:1748254102.151943   87575 buffer_comparator.cc:156] Difference at 8: 0.0130844, expected -nan\n",
      "E0000 00:00:1748254102.151946   87575 buffer_comparator.cc:156] Difference at 10: 0.0575867, expected -nan\n",
      "E0000 00:00:1748254102.151948   87575 buffer_comparator.cc:156] Difference at 12: 0.102722, expected -nan\n",
      "E0000 00:00:1748254102.151950   87575 buffer_comparator.cc:156] Difference at 14: 0.0192719, expected -nan\n",
      "E0000 00:00:1748254102.151952   87575 buffer_comparator.cc:156] Difference at 16: 0.0931396, expected -nan\n",
      "E0000 00:00:1748254102.151954   87575 buffer_comparator.cc:156] Difference at 18: 0.0354614, expected -nan\n",
      "2025-05-26 10:08:22.152851: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[516,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[516,1,100,1]{3,2,1,0} %bitcast.5674, f16[128,1,3,1]{3,2,1,0} %bitcast.5678, f16[128]{0} %bitcast.5681), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:22.153156: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:22.153162: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:22.153167: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:22.153168: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:22.153191: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   54/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:31\u001b[0m 21ms/step - accuracy: 0.1305 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254109.923633   87577 buffer_comparator.cc:156] Difference at 0: 0.0346375, expected -nan\n",
      "E0000 00:00:1748254109.923707   87577 buffer_comparator.cc:156] Difference at 2: 0.0725708, expected -nan\n",
      "E0000 00:00:1748254109.923719   87577 buffer_comparator.cc:156] Difference at 4: 0.045929, expected -nan\n",
      "E0000 00:00:1748254109.923722   87577 buffer_comparator.cc:156] Difference at 6: 0.0869751, expected -nan\n",
      "E0000 00:00:1748254109.923724   87577 buffer_comparator.cc:156] Difference at 8: 0.0386047, expected -nan\n",
      "E0000 00:00:1748254109.923726   87577 buffer_comparator.cc:156] Difference at 10: 0.0725098, expected -nan\n",
      "E0000 00:00:1748254109.923730   87577 buffer_comparator.cc:156] Difference at 12: 0.0678711, expected -nan\n",
      "E0000 00:00:1748254109.923732   87577 buffer_comparator.cc:156] Difference at 14: 0.0246429, expected -nan\n",
      "E0000 00:00:1748254109.923735   87577 buffer_comparator.cc:156] Difference at 16: 0.0995483, expected -nan\n",
      "E0000 00:00:1748254109.923737   87577 buffer_comparator.cc:156] Difference at 18: 0.0672607, expected -nan\n",
      "2025-05-26 10:08:29.923773: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[515,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[515,1,100,1]{3,2,1,0} %bitcast.5674, f16[128,1,3,1]{3,2,1,0} %bitcast.5678, f16[128]{0} %bitcast.5681), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:29.923798: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:29.923802: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:29.923805: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:29.923807: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:29.923818: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   58/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:10\u001b[0m 93ms/step - accuracy: 0.1304 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254114.428431   87577 buffer_comparator.cc:156] Difference at 0: 0.0701294, expected -nan\n",
      "E0000 00:00:1748254114.428549   87577 buffer_comparator.cc:156] Difference at 2: 0.00673294, expected -nan\n",
      "E0000 00:00:1748254114.428566   87577 buffer_comparator.cc:156] Difference at 4: 0.103821, expected -nan\n",
      "E0000 00:00:1748254114.428572   87577 buffer_comparator.cc:156] Difference at 6: 0.0821533, expected -nan\n",
      "E0000 00:00:1748254114.428577   87577 buffer_comparator.cc:156] Difference at 8: 0.0717163, expected -nan\n",
      "E0000 00:00:1748254114.428581   87577 buffer_comparator.cc:156] Difference at 10: 0.0334167, expected -nan\n",
      "E0000 00:00:1748254114.428586   87577 buffer_comparator.cc:156] Difference at 12: 0.105591, expected -nan\n",
      "E0000 00:00:1748254114.428591   87577 buffer_comparator.cc:156] Difference at 14: 0.0542908, expected -nan\n",
      "E0000 00:00:1748254114.428595   87577 buffer_comparator.cc:156] Difference at 16: 0.101257, expected -nan\n",
      "E0000 00:00:1748254114.428599   87577 buffer_comparator.cc:156] Difference at 18: 0.0583496, expected -nan\n",
      "2025-05-26 10:08:34.428643: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[518,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[518,1,100,1]{3,2,1,0} %bitcast.5672, f16[128,1,3,1]{3,2,1,0} %bitcast.5676, f16[128]{0} %bitcast.5679), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:34.428666: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:34.428670: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:34.428676: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:34.428679: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:34.428693: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  104/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30:36\u001b[0m 98ms/step - accuracy: 0.1301 - loss: nan "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254118.695867   87577 buffer_comparator.cc:156] Difference at 0: 0.104553, expected -nan\n",
      "E0000 00:00:1748254118.695938   87577 buffer_comparator.cc:156] Difference at 2: 0.00839233, expected -nan\n",
      "E0000 00:00:1748254118.695949   87577 buffer_comparator.cc:156] Difference at 4: 0.0127792, expected -nan\n",
      "E0000 00:00:1748254118.695952   87577 buffer_comparator.cc:156] Difference at 6: 0.0423889, expected -nan\n",
      "E0000 00:00:1748254118.695954   87577 buffer_comparator.cc:156] Difference at 8: 0.00917053, expected -nan\n",
      "E0000 00:00:1748254118.695956   87577 buffer_comparator.cc:156] Difference at 10: 0.0814819, expected -nan\n",
      "E0000 00:00:1748254118.695958   87577 buffer_comparator.cc:156] Difference at 12: 0.0527039, expected -nan\n",
      "E0000 00:00:1748254118.695962   87577 buffer_comparator.cc:156] Difference at 14: 0.0509644, expected -nan\n",
      "E0000 00:00:1748254118.695964   87577 buffer_comparator.cc:156] Difference at 16: 0.0311279, expected -nan\n",
      "E0000 00:00:1748254118.695966   87577 buffer_comparator.cc:156] Difference at 18: 0.0541992, expected -nan\n",
      "2025-05-26 10:08:38.696040: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[517,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[517,1,100,1]{3,2,1,0} %bitcast.5674, f16[128,1,3,1]{3,2,1,0} %bitcast.5678, f16[128]{0} %bitcast.5681), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:38.696060: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:38.696062: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:38.696090: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:38.696105: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:38.696118: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  117/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:20\u001b[0m 133ms/step - accuracy: 0.1302 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254126.804502   87577 buffer_comparator.cc:156] Difference at 0: 0.0447998, expected -nan\n",
      "E0000 00:00:1748254126.804586   87577 buffer_comparator.cc:156] Difference at 2: 0.0888062, expected -nan\n",
      "E0000 00:00:1748254126.804605   87577 buffer_comparator.cc:156] Difference at 4: 0.108093, expected -nan\n",
      "E0000 00:00:1748254126.804611   87577 buffer_comparator.cc:156] Difference at 6: 0.05896, expected -nan\n",
      "E0000 00:00:1748254126.804615   87577 buffer_comparator.cc:156] Difference at 8: 0.0432739, expected -nan\n",
      "E0000 00:00:1748254126.804618   87577 buffer_comparator.cc:156] Difference at 10: 0.0366516, expected -nan\n",
      "E0000 00:00:1748254126.804620   87577 buffer_comparator.cc:156] Difference at 12: 0.00644302, expected -nan\n",
      "E0000 00:00:1748254126.804622   87577 buffer_comparator.cc:156] Difference at 14: 0.0888672, expected -nan\n",
      "E0000 00:00:1748254126.804624   87577 buffer_comparator.cc:156] Difference at 16: 0.0249176, expected -nan\n",
      "E0000 00:00:1748254126.804627   87577 buffer_comparator.cc:156] Difference at 18: 0.0336914, expected -nan\n",
      "2025-05-26 10:08:46.804830: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[514,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[514,1,100,1]{3,2,1,0} %bitcast.5674, f16[128,1,3,1]{3,2,1,0} %bitcast.5678, f16[128]{0} %bitcast.5681), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:46.804893: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:46.804897: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:46.804902: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:46.804904: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:46.804921: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  161/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:08\u001b[0m 145ms/step - accuracy: 0.1318 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254132.365750   87576 buffer_comparator.cc:156] Difference at 0: 0.0765381, expected -nan\n",
      "E0000 00:00:1748254132.365855   87576 buffer_comparator.cc:156] Difference at 2: 0.0891724, expected -nan\n",
      "E0000 00:00:1748254132.365869   87576 buffer_comparator.cc:156] Difference at 4: 0.0975952, expected -nan\n",
      "E0000 00:00:1748254132.365874   87576 buffer_comparator.cc:156] Difference at 6: 0.00751877, expected -nan\n",
      "E0000 00:00:1748254132.365879   87576 buffer_comparator.cc:156] Difference at 8: 0.0709229, expected -nan\n",
      "E0000 00:00:1748254132.365882   87576 buffer_comparator.cc:156] Difference at 10: 0.0205688, expected -nan\n",
      "E0000 00:00:1748254132.365887   87576 buffer_comparator.cc:156] Difference at 12: 0.0439758, expected -nan\n",
      "E0000 00:00:1748254132.365890   87576 buffer_comparator.cc:156] Difference at 14: 0.0222626, expected -nan\n",
      "E0000 00:00:1748254132.365894   87576 buffer_comparator.cc:156] Difference at 16: 0.019577, expected -nan\n",
      "E0000 00:00:1748254132.365898   87576 buffer_comparator.cc:156] Difference at 18: 0.0173798, expected -nan\n",
      "2025-05-26 10:08:52.366562: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[513,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[513,1,100,1]{3,2,1,0} %bitcast.5672, f16[128,1,3,1]{3,2,1,0} %bitcast.5676, f16[128]{0} %bitcast.5679), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:52.366896: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:52.366905: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:52.366910: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:52.366912: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:52.366925: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  175/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49:37\u001b[0m 160ms/step - accuracy: 0.1326 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254138.559726   87578 buffer_comparator.cc:156] Difference at 0: 0.0134048, expected -nan\n",
      "E0000 00:00:1748254138.559804   87578 buffer_comparator.cc:156] Difference at 2: 0.032959, expected -nan\n",
      "E0000 00:00:1748254138.559814   87578 buffer_comparator.cc:156] Difference at 4: 0.0551453, expected -nan\n",
      "E0000 00:00:1748254138.559817   87578 buffer_comparator.cc:156] Difference at 6: 0.0138168, expected -nan\n",
      "E0000 00:00:1748254138.559819   87578 buffer_comparator.cc:156] Difference at 8: 0.0773926, expected -nan\n",
      "E0000 00:00:1748254138.559821   87578 buffer_comparator.cc:156] Difference at 10: 0.0374451, expected -nan\n",
      "E0000 00:00:1748254138.559823   87578 buffer_comparator.cc:156] Difference at 12: 0.034668, expected -nan\n",
      "E0000 00:00:1748254138.559825   87578 buffer_comparator.cc:156] Difference at 14: 0.0387573, expected -nan\n",
      "E0000 00:00:1748254138.559827   87578 buffer_comparator.cc:156] Difference at 16: 0.043396, expected -nan\n",
      "E0000 00:00:1748254138.559829   87578 buffer_comparator.cc:156] Difference at 18: 0.0315247, expected -nan\n",
      "2025-05-26 10:08:58.560735: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[520,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[520,1,100,1]{3,2,1,0} %bitcast.5649, f16[128,1,3,1]{3,2,1,0} %bitcast.5653, f16[128]{0} %bitcast.5656), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:08:58.560799: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:08:58.560805: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:08:58.560809: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:08:58.560811: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:08:58.560823: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  225/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47:24\u001b[0m 153ms/step - accuracy: 0.1344 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254142.988683   87577 buffer_comparator.cc:156] Difference at 0: 0.0141449, expected -nan\n",
      "E0000 00:00:1748254142.988817   87577 buffer_comparator.cc:156] Difference at 2: 0.00693893, expected -nan\n",
      "E0000 00:00:1748254142.988872   87577 buffer_comparator.cc:156] Difference at 4: 0.0202179, expected -nan\n",
      "E0000 00:00:1748254142.988889   87577 buffer_comparator.cc:156] Difference at 6: 0.0962524, expected -nan\n",
      "E0000 00:00:1748254142.988894   87577 buffer_comparator.cc:156] Difference at 8: 0.0795288, expected -nan\n",
      "E0000 00:00:1748254142.988897   87577 buffer_comparator.cc:156] Difference at 10: 0.0673828, expected -nan\n",
      "E0000 00:00:1748254142.988901   87577 buffer_comparator.cc:156] Difference at 12: 0.0961914, expected -nan\n",
      "E0000 00:00:1748254142.988905   87577 buffer_comparator.cc:156] Difference at 14: 0.100464, expected -nan\n",
      "E0000 00:00:1748254142.988908   87577 buffer_comparator.cc:156] Difference at 16: 0.0310364, expected -nan\n",
      "E0000 00:00:1748254142.988911   87577 buffer_comparator.cc:156] Difference at 18: 0.0966797, expected -nan\n",
      "2025-05-26 10:09:02.989569: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[519,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[519,1,100,1]{3,2,1,0} %bitcast.5674, f16[128,1,3,1]{3,2,1,0} %bitcast.5678, f16[128]{0} %bitcast.5681), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:09:02.989588: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:09:02.989591: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:09:02.989594: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:09:02.989596: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:09:02.989608: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  728/18825\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:15\u001b[0m 77ms/step - accuracy: 0.1394 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254164.663744   87576 buffer_comparator.cc:156] Difference at 0: 0.0791626, expected -nan\n",
      "E0000 00:00:1748254164.663811   87576 buffer_comparator.cc:156] Difference at 2: 0.0888062, expected -nan\n",
      "E0000 00:00:1748254164.663823   87576 buffer_comparator.cc:156] Difference at 4: 0.0611267, expected -nan\n",
      "E0000 00:00:1748254164.663827   87576 buffer_comparator.cc:156] Difference at 6: 0.0560303, expected -nan\n",
      "E0000 00:00:1748254164.663829   87576 buffer_comparator.cc:156] Difference at 8: 0.0624695, expected -nan\n",
      "E0000 00:00:1748254164.663832   87576 buffer_comparator.cc:156] Difference at 10: 0.0648193, expected -nan\n",
      "E0000 00:00:1748254164.663834   87576 buffer_comparator.cc:156] Difference at 12: 0.024704, expected -nan\n",
      "E0000 00:00:1748254164.663836   87576 buffer_comparator.cc:156] Difference at 14: 0.0946045, expected -nan\n",
      "E0000 00:00:1748254164.663838   87576 buffer_comparator.cc:156] Difference at 16: 0.0068512, expected -nan\n",
      "E0000 00:00:1748254164.663841   87576 buffer_comparator.cc:156] Difference at 18: 0.0340271, expected -nan\n",
      "2025-05-26 10:09:24.663879: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[512,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[512,1,100,1]{3,2,1,0} %bitcast.5649, f16[128,1,3,1]{3,2,1,0} %bitcast.5653, f16[128]{0} %bitcast.5656), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:09:24.663898: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:09:24.663901: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:09:24.663904: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:09:24.663906: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:09:24.663918: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  968/18825\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:07\u001b[0m 68ms/step - accuracy: 0.1402 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1748254175.122319   87575 buffer_comparator.cc:156] Difference at 0: 0.0323181, expected -nan\n",
      "E0000 00:00:1748254175.122423   87575 buffer_comparator.cc:156] Difference at 2: 0.041626, expected -nan\n",
      "E0000 00:00:1748254175.122439   87575 buffer_comparator.cc:156] Difference at 4: 0.0429688, expected -nan\n",
      "E0000 00:00:1748254175.122444   87575 buffer_comparator.cc:156] Difference at 6: 0.0248108, expected -nan\n",
      "E0000 00:00:1748254175.122448   87575 buffer_comparator.cc:156] Difference at 8: 0.0596924, expected -nan\n",
      "E0000 00:00:1748254175.122451   87575 buffer_comparator.cc:156] Difference at 10: 0.0303802, expected -nan\n",
      "E0000 00:00:1748254175.122455   87575 buffer_comparator.cc:156] Difference at 12: 0.0427551, expected -nan\n",
      "E0000 00:00:1748254175.122459   87575 buffer_comparator.cc:156] Difference at 14: 0.0111389, expected -nan\n",
      "E0000 00:00:1748254175.122462   87575 buffer_comparator.cc:156] Difference at 16: 0.0837402, expected -nan\n",
      "E0000 00:00:1748254175.122465   87575 buffer_comparator.cc:156] Difference at 18: 0.0688477, expected -nan\n",
      "2025-05-26 10:09:35.122500: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:764] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "%cudnn-conv-bias-activation.3 = (f16[521,1,100,128]{3,2,1,0}, u8[0]{0}) custom-call(f16[521,1,100,1]{3,2,1,0} %bitcast.5672, f16[128,1,3,1]{3,2,1,0} %bitcast.5676, f16[128]{0} %bitcast.5679), window={size=1x3 pad=0_0x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_11_1/conv1d_11_1/convolution\" source_file=\"/home/hoangvn/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} for eng31{k2=2,k6=0,k13=2,k14=0,k22=2} vs eng4{k2=3,k4=2,k5=3,k6=3,k7=2}\n",
      "2025-05-26 10:09:35.122517: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:323] Device: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "2025-05-26 10:09:35.122521: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:324] Platform: Compute Capability 7.5\n",
      "2025-05-26 10:09:35.122568: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:325] Driver: 12.8.0\n",
      "2025-05-26 10:09:35.122577: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:326] Runtime: 12.1.0\n",
      "2025-05-26 10:09:35.122590: E external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:331] cudnn version: 9.3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1555/18825\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:50\u001b[0m 62ms/step - accuracy: 0.1411 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 82\u001b[0m\n\u001b[1;32m     73\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     74\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     75\u001b[0m     ModelCheckpoint(model_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_best.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     76\u001b[0m     csv_logger\n\u001b[1;32m     77\u001b[0m ]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# log_dir = \"Tensorflow_log/profile\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Log - tensorflow, bottle neck hay không\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# tf.profiler.experimental.start(log_dir)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# tf.profiler.experimental.stop()\u001b[39;00m\n\u001b[1;32m     86\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m ):\n\u001b[1;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/doan/lib/python3.9/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "########### Enable XLA ###############\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "\n",
    "########### Nếu không dùng XLA ###########\n",
    "# import os\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# shape\n",
    "features, labels = next(iter(train_gen))\n",
    "input_shape = (features.shape[1], 1)\n",
    "output_shape = labels.shape[1]\n",
    "\n",
    "print(f\"Input Shape: {input_shape} \\n Output Shape: {output_shape}\")\n",
    "\n",
    "# Định nghĩa mô hình CNN\n",
    "# VGG, ...\n",
    "# Conv2D, tabular, ...\n",
    "# HE, tính tương thích của HE với CNN\n",
    "# Tính chất data in, out; Học tăng cường\n",
    "start_time = datetime.now()\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     layers.Input(shape=input_shape),\n",
    "#     layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv1D(filters=128, kernel_size=3,  padding=\"same\",activation=\"relu\"),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling1D(pool_size=2),\n",
    "#     layers.Dropout(0.1),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dense(1, activation='sigmoid') #softmax\n",
    "# ])\n",
    "# adam_optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    # layers.Conv1D(filters=128, kernel_size=3,  padding=\"same\",activation=\"relu\"),\n",
    "    # layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(output_shape, activation='softmax') #dtype='float32'\n",
    "])\n",
    "adam_optimizer = optimizers.Adam(learning_rate=0.002)\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#sparse khi không onehot\n",
    "# for batch in dataloader:\n",
    "#     X_batch = batch[:, :-1]\n",
    "#     y_batch = batch[:, -1]\n",
    "#     y_onehot = to_categorical(y_batch, num_classes=10)\n",
    "    \n",
    "#     model.train_on_batch(X_batch, y_onehot, verbose=1)\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "csv_logger = CSVLogger(\"Centralized_Log/\"+ datetime.now().strftime(\"Month%mDay%d__%Hh%Mp\")+\".csv\" , append=True)\n",
    "\n",
    "model_path =  \"Centralized_Model/cnn_model_\" + datetime.now().strftime(\"Month%mDay%d__%Hh%Mp\")\n",
    "print(\"Model Path: \", model_path)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
    "    ModelCheckpoint(model_path+\"_best.keras\", monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    csv_logger\n",
    "]\n",
    "# log_dir = \"Tensorflow_log/profile\"\n",
    "\n",
    "# Log - tensorflow, bottle neck hay không\n",
    "# tf.profiler.experimental.start(log_dir)\n",
    "model.fit(train_gen, epochs=10, validation_data=val_gen, \n",
    "          validation_steps=validation_steps, steps_per_epoch= steps_per_epoch, verbose = 1, callbacks=callbacks)\n",
    "# tf.profiler.experimental.stop()\n",
    "\n",
    "end_time = datetime.now()\n",
    "simulated_time = end_time - start_time\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(model_path+\".keras\")\n",
    "\n",
    "print(f\"Simulated time: {simulated_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe9e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
