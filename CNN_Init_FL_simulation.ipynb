{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/hoang/FileCSV_DACN_2025/file1.csv', 'C:/Users/hoang/FileCSV_DACN_2025/file2.csv', 'C:/Users/hoang/FileCSV_DACN_2025/file3.csv']\n",
      "id.orig_h         float64\n",
      "id.orig_p         float64\n",
      "id.resp_h         float64\n",
      "id.resp_p         float64\n",
      "duration          float64\n",
      "orig_bytes        float64\n",
      "resp_bytes        float64\n",
      "conn_state        float64\n",
      "missed_bytes      float64\n",
      "history           float64\n",
      "orig_pkts         float64\n",
      "orig_ip_bytes     float64\n",
      "resp_pkts         float64\n",
      "resp_ip_bytes     float64\n",
      "detailed-label      int64\n",
      "proto_icmp          int64\n",
      "proto_tcp           int64\n",
      "proto_udp           int64\n",
      "service_dhcp        int64\n",
      "service_dns         int64\n",
      "service_http        int64\n",
      "service_irc         int64\n",
      "service_ssh         int64\n",
      "service_ssl         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "# temp_dir = \"C:/Users/hoang/FileCSV_DACN_2025/ddos_dos_\"\n",
    "\n",
    "input_files = [f\"file{i+1}.csv\" for i in range(3)]\n",
    "temp_dir =  \"C:/Users/hoang/FileCSV_DACN_2025/\"\n",
    "\n",
    "input_files = [temp_dir + output_file for output_file in input_files]\n",
    "print(input_files)\n",
    "df = [dk.read_csv(file) for file in input_files]\n",
    "for index in range(len(df)):\n",
    "    df[index]= df[index].drop(columns='label')\n",
    "# test_df = dk.read_csv(\"FL_Dataset/test.csv\")\n",
    "\n",
    "# input_zip = \"/mnt/c/Users/hoang/FileCSV_DACN_2025/2Type.zip\"\n",
    "# csv_files = []\n",
    "# with zipfile.ZipFile(input_zip, 'r') as z:\n",
    "#     csv_files = [f for f in z.namelist() if f.endswith('.csv')]\n",
    "# print(csv_files)\n",
    "# df = [dk.read_csv(f'zip://{file}::{input_zip}') for file in csv_files]\n",
    "# print(df[0].shape)\n",
    "\n",
    "print(df[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Len:  23\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "ratio_test_all = 0.2\n",
    "\n",
    "from dask_ml.model_selection import train_test_split \n",
    "# Split \n",
    "# train_df, val_test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "# val_df, test_df = train_test_split(val_test_df, test_size=0.75, random_state=42)\n",
    "\n",
    "# # load từng batch\n",
    "features_len = len(df[1].columns)-1\n",
    "print(\"Feature Len: \",features_len)\n",
    "def dask_to_tf_dataset(dask_df, batch_size, num_classes): \n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch=batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "\n",
    "            X = batch.drop(columns='detailed-label').values.astype(np.float32)\n",
    "            y = batch['detailed-label'].values\n",
    "            y_onehot = to_categorical(y, num_classes=num_classes)  \n",
    "\n",
    "            num_splits = max(1, len(X) // batch_size)  # Đảm bảo không chia nhỏ quá mức\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y_onehot, num_splits)\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, features_len), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.int32),\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1, test_df1 = df1.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "# train_df2, test_df2 = df2.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "# train_df3, test_df3 = df3.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "batch_size = 512\n",
    "train_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs= []\n",
    "for dff in df:\n",
    "    train_df, val_test_df =dff.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "    test_df, val_df = val_test_df.random_split([1-0.25, 0.25])\n",
    "    train_dfs.append(train_df)\n",
    "    val_dfs.append(val_df)\n",
    "    test_dfs.append(test_df)\n",
    "   \n",
    "\n",
    "train_gens = [dask_to_tf_dataset(train_df, batch_size=batch_size,num_classes=3).repeat() for train_df in train_dfs]\n",
    "val_gens = [dask_to_tf_dataset(val_df , batch_size=batch_size, num_classes=3) for val_df in val_dfs]\n",
    "test_gens = [dask_to_tf_dataset(test_df , batch_size=batch_size, num_classes=3) for test_df in test_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "#\n",
    "from server import Server\n",
    "from client import Client\n",
    "num_servers = 1\n",
    "num_clients = 3\n",
    "\n",
    "stepsPerEpoch_Clients = [40, 40, 40] #[int( np.ceil(train_dfs[index].shape[0])/batch_size) for index in range(num_clients)]\n",
    "stepsValidate_Clients = [5,5,5] #[int( np.ceil(val_dfs[index].shape[0])/batch_size) for index in range(num_clients)]\n",
    "stepsTest_Clients = [10,10,10] #[int( np.ceil(test_dfs[index].shape[0])/batch_size) for index in range(num_clients)]\n",
    "# int(np.ceil(test_df.shape[0]))\n",
    "active_servers_list  = ['server_'+str(i)\\\n",
    "                        for i in range(num_servers)]\n",
    "active_clients_list  = ['client_'+str(i)\\\n",
    "                        for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['server_0']\n",
      "['client_0', 'client_1', 'client_2']\n",
      "<class 'dict'>\n",
      "Agent_Dict:  <client.Client object at 0x0000020A931AD490>\n",
      "<server.Server object at 0x0000020A913ACA50>\n"
     ]
    }
   ],
   "source": [
    "print(active_servers_list)\n",
    "print(active_clients_list)\n",
    "\n",
    "def init_he_context():\n",
    "    \"\"\"Thiết lập context mã hóa đồng hình\"\"\"\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS, # ckks cho số thực, bfv cho int\n",
    "        poly_modulus_degree= 32768,   #8192,\n",
    "        coeff_mod_bit_sizes=[60, 40,40, 40, 60]\n",
    "    )\n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**40\n",
    "    return context\n",
    "\n",
    "context = init_he_context()\n",
    "agents_dict= {}\n",
    "serverObjects={}\n",
    "clientObjects={}\n",
    "serverObjects = {server_name: Server(server_name=server_name, \\\n",
    "                        active_clients_list=active_clients_list) \\\n",
    "                        for server_name in active_servers_list}\n",
    "print(type(serverObjects))\n",
    "clientObjects = {client_name: Client(client_name, train_gens[clientID], val_gens[clientID], test_gens[clientID], \\\n",
    "                        stepsPerEpoch_Clients[clientID],stepsValidate_Clients[clientID], stepsTest_Clients[clientID],\\\n",
    "                        active_clients_list = active_clients_list, he_context=context) \\\n",
    "                        for clientID, client_name in enumerate(active_clients_list)}\n",
    "\n",
    "# for index, client_name in enumerate(active_clients_list):\n",
    "#     clientObjects[client_name].set_steps_per_epoch(stepsPerEpoch_Clients[index])\n",
    "#     clientObjects[client_name].get_steps_per_epoch()\n",
    "#     clientObjects[client_name].set_validation_steps(stepsValidate_Clients[index])\n",
    "#     clientObjects[client_name].get_validation_steps()\n",
    "#     clientObjects[client_name].set_test_steps(stepsTest_Clients)\n",
    "#     clientObjects[client_name].get_test_steps()\n",
    "    \n",
    "# lưu dict\n",
    "agents_dict['server'] = serverObjects\n",
    "agents_dict['client'] = clientObjects\n",
    "\n",
    "# init agents_dict vừa tạo vào client, server\n",
    "for agent_name, agent in serverObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "for agent_name, agent in clientObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "\n",
    "client_name = 'client_1'\n",
    "print(\"Agent_Dict: \", agents_dict['client'][client_name])\n",
    "\n",
    "server = agents_dict['server']['server_0']\n",
    "print(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================== Đang chạy Iteration 1 ======================================\n",
      "Epoch 1/4\n",
      "Epoch 1/4\n",
      "Epoch 1/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 187ms/step - accuracy: 0.7318 - loss: 0.6905 - val_accuracy: 0.1021 - val_loss: 5.2904\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 177ms/step - accuracy: 0.6978 - loss: 0.7802 - val_accuracy: 0.0534 - val_loss: 5.4077\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 180ms/step - accuracy: 0.7739 - loss: 0.6395 - val_accuracy: 0.0554 - val_loss: 6.1485\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7381 - loss: 0.7796 - val_accuracy: 0.1095 - val_loss: 3.9680\n",
      "Epoch 3/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.8839 - loss: 0.3703 - val_accuracy: 0.0564 - val_loss: 7.1473\n",
      "Epoch 3/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.9897 - loss: 0.0727 - val_accuracy: 0.0542 - val_loss: 11.9557\n",
      "Epoch 3/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - accuracy: 0.7443 - loss: 0.5821 - val_accuracy: 0.1291 - val_loss: 4.3771\n",
      "Epoch 4/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.8697 - loss: 0.5212 - val_accuracy: 0.0631 - val_loss: 5.9226\n",
      "Epoch 4/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.7644 - loss: 0.7087 - val_accuracy: 0.0694 - val_loss: 7.7780\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.7837 - loss: 0.5853Epoch 4/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7926 - loss: 0.6535 - val_accuracy: 0.1566 - val_loss: 4.0940\n",
      "Come done model fit\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "<class 'datetime.timedelta'>\n",
      "client_0End Produce Weights\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 265ms/step - accuracy: 0.8441 - loss: 0.4944 - val_accuracy: 0.0659 - val_loss: 7.7739\n",
      "Come done model fit\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "<class 'datetime.timedelta'>\n",
      "client_1End Produce Weights\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 294ms/step - accuracy: 0.8967 - loss: 0.3708 - val_accuracy: 0.0772 - val_loss: 6.2152\n",
      "Come done model fit\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "<class 'datetime.timedelta'>\n",
      "client_2End Produce Weights\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0759 - loss: 7.7280\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0800 - loss: 6.2691\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.0963 - loss: 4.5427\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0524 - loss: 53.2754\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.5864 - loss: 3.4193Arguments:  Performance Metrics for client_2 on iteration 1 \n",
      "------------------------------------------- \n",
      "local accuracy: 0.0760233923792839 \n",
      "local loss: 6.292547702789307 \n",
      "global accuracy: 0.049320388585329056 \n",
      "global_loss: 53.48986053466797 \n",
      "local compute time: 0:00:44.169954 \n",
      "Simulated time to receive global weights: 0:00:50.345682 \n",
      " \n",
      "\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5905 - loss: 3.2879\n",
      "Arguments:  Performance Metrics for client_1 on iteration 1 \n",
      "------------------------------------------- \n",
      "local accuracy: 0.0781676396727562 \n",
      "local loss: 7.687297344207764 \n",
      "global accuracy: 0.5842718482017517 \n",
      "global_loss: 3.3645248413085938 \n",
      "local compute time: 0:00:39.791778 \n",
      "Simulated time to receive global weights: 0:00:50.345682 \n",
      " \n",
      "\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0536 - loss: 45.1823\n",
      "Arguments:  Performance Metrics for client_0 on iteration 1 \n",
      "------------------------------------------- \n",
      "local accuracy: 0.07669902592897415 \n",
      "local loss: 4.546045780181885 \n",
      "global accuracy: 0.06439688801765442 \n",
      "global_loss: 44.774208068847656 \n",
      "local compute time: 0:00:35.310096 \n",
      "Simulated time to receive global weights: 0:00:50.345682 \n",
      " \n",
      "\n",
      "[client_0] :Simulated time for client set() to finish iteration 1: 0:01:41.544853\n",
      "\n",
      "[client_1] :Simulated time for client set() to finish iteration 1: 0:01:41.544853\n",
      "\n",
      "[client_2] :Simulated time for client set() to finish iteration 1: 0:01:41.544853\n",
      "\n",
      "====================================== Kết thúc Iteration 1 ======================================\n",
      "====================================== Đang chạy Iteration 2 ======================================\n",
      "2 client_0 Model update params!2 client_1 Model update params!\n",
      "\n",
      "2 client_2 Model update params!\n",
      "Epoch 1/4\n",
      "Epoch 1/4\n",
      "Epoch 1/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.9557 - loss: 0.1404 - val_accuracy: 0.0827 - val_loss: 6.5758\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 171ms/step - accuracy: 0.9810 - loss: 0.1407 - val_accuracy: 0.0663 - val_loss: 7.0344\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 169ms/step - accuracy: 0.9246 - loss: 0.2415 - val_accuracy: 0.1147 - val_loss: 1.8859\n",
      "Epoch 2/4\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8065 - loss: 0.6185"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    server.InitLoop()\n",
    "    server.final_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14h24p__15-04/model_1.keras', '14h24p__15-04/model_2.keras', '14h24p__15-04/model_3.keras', '14h24p__15-04/model_4.keras', '14h24p__15-04/model_5.keras']\n",
      "[<Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>, <Sequential name=sequential, built=True>]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# tempdirs = [\"D:/DoAnChuyenNganh_Train/client_0_log/11h18p__02-04-2025/\", \"D:/DoAnChuyenNganh_Train/client_1_log/11h18p__02-04-2025/\",  \"D:/DoAnChuyenNganh_Train/client_2_log/11h18p__02-04-2025/\"]\n",
    "timeFolder=\"14h24p__15-04/\"\n",
    "tempdirs = [f\"D:/DoAnChuyenNganh_Train/log/client_{i}_log/\" for i in range(len(active_clients_list))]\n",
    "\n",
    "\n",
    "model_names =[timeFolder+f\"model_{i+1}.keras\" for i in range(5)]\n",
    "print(model_names)\n",
    "models = {}\n",
    "\n",
    "for i, client_name in enumerate(active_clients_list):\n",
    "    models[client_name] = [load_model(tempdirs[i]+model_name) for model_name in model_names]\n",
    "print (models['client_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Batch Each Client:  [4159, 8325, 12480]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_batch_test_eachClient  =  []\n",
    "for index, test_df in enumerate(test_dfs):\n",
    "    num_samples_test = test_df.shape[0].compute()\n",
    "    # Tính số batch\n",
    "    num_batches_test = int(np.ceil(num_samples_test / batch_size))\n",
    "    num_batch_test_eachClient.append(num_batches_test)\n",
    "\n",
    "print(\"Num Batch Each Client: \", num_batch_test_eachClient)\n",
    "X_tests = {}\n",
    "Y_tests = {}\n",
    "Y_preds= {}\n",
    "for i, client_name in enumerate(active_clients_list):\n",
    "    Y_tests[client_name]={}\n",
    "    Y_preds[client_name]={}\n",
    "\n",
    "# for i, client_name in enumerate(active_clients_list):\n",
    "#     X_test = []\n",
    "#     y_test = []\n",
    "#     for X_batch, y_batch in test_gens[i].take(num_batch_test_eachClient[i]):\n",
    "#         X_test.extend(X_batch.numpy().flatten())\n",
    "#         y_test.extend(y_batch.numpy().flatten())\n",
    "#         y_pred = []\n",
    "#         for iteration in range(5):    \n",
    "#     # .as_numpy_iterator():\n",
    "#         # # take(12000):\n",
    "#         # X_test_list.append(X_batch.numpy())\n",
    "#         # y_test_list.append(y_batch.numpy())  # .numpy()\n",
    "\n",
    "#         # # Gộp tất cả batch lại\n",
    "#         # X_test = np.concatenate(X_test_list, axis=0)\n",
    "#         # y_test = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "#         # # Nếu y_test đang ở dạng one-hot, chuyển về dạng số\n",
    "#         # y_test = np.argmax(y_test, axis=1)\n",
    "#             y_pred_pre = models[client_name][iteration].predict(X_batch, verbose=0)\n",
    "#             y_pred.extend((y_pred_pre > 0.5).astype(int).flatten())\n",
    "    \n",
    "#         Y_tests[client_name][iteration] = y_test\n",
    "#         Y_preds[client_name][iteration] = y_pred\n",
    "    \n",
    "# print(Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137239\n",
      "<Sequential name=sequential, built=True>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 320, but received input with shape (32, 128)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 23), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(Iterations)):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(models[client_name][iteration])\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     y_pred_pre = \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     y_pred = (y_pred_pre > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m).flatten()\n\u001b[32m     29\u001b[39m     precisions.append(precision_score(y_test, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hoang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hoang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec.axes.items():\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    224\u001b[39m             value,\n\u001b[32m    225\u001b[39m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    226\u001b[39m         }:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    228\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    229\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbut received input with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    233\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 320, but received input with shape (32, 128)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 23), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Client 0\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(5)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for X_batch, y_batch in test_gens[i].take(num_batch_test_eachClient[0]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "print(len(X_test))\n",
    "for iteration in range(len(Iterations)):\n",
    "    print(models[client_name][iteration])\n",
    "    y_pred_pre = models[client_name][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = (y_pred_pre > 0.5).astype(int).flatten()\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='binary'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='binary'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 0\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types = ['BenignTraffic', 'DoS&DDoS']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 0\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# attack_types = ['BenignTraffic', 'DDoS-ICMP_Flood', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', \n",
    "#                    'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood']\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 0\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "y_pred = []\n",
    "\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(5)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "print(num_batch_test_eachClient[1])\n",
    "\n",
    "for X_batch, y_batch in test_gens[1].take(num_batch_test_eachClient[1]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "for iteration in range(len(Iterations)):\n",
    "    y_pred_pre = models['client_1'][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = (y_pred_pre > 0.5).astype(int).flatten()\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='binary'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='binary'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='binary'))\n",
    "    \n",
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 1\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types = ['BenignTraffic', 'DoS&DDoS']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 1\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "# attack_types = ['BenignTraffic', 'DDoS-ICMP_Flood', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', \n",
    "#                    'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood']\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 1\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "y_pred = []\n",
    "Iterations = [f\"Iteration {index+1}\" for index in range(5)]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for X_batch, y_batch in test_gens[2].take(num_batch_test_eachClient[2]):\n",
    "    X_test.append(X_batch.numpy())\n",
    "    y_test.append(y_batch.numpy())\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "for iteration in range(len(Iterations)):\n",
    "    y_pred_pre = models['client_2'][iteration].predict(X_test, verbose=1)\n",
    "    y_pred = (y_pred_pre > 0.5).astype(int).flatten()\n",
    "    \n",
    "    precisions.append(precision_score(y_test, y_pred, average='binary'))\n",
    "    recalls.append(recall_score(y_test, y_pred, average='binary'))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='binary'))\n",
    "    \n",
    "print(\"Precision Score: \", precisions)\n",
    "print(\"Recall Score: \", recalls)\n",
    "print(\"F1 Score: \", f1s)  \n",
    "\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Iterations, precisions, marker='o', linestyle='-', label=\"Precision\", color='blue')\n",
    "plt.plot(Iterations, recalls, marker='s', linestyle='-', label=\"Recall\", color='red')\n",
    "plt.plot(Iterations, f1s, marker='^', linestyle='-', label=\"F1-score\", color='green')\n",
    "\n",
    "# Thêm tiêu đề và nhãn\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1-score over different iterations _ CLIENT 2\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)  # Giới hạn từ 0 đến 1\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "attack_types = ['BenignTraffic', 'DoS&DDoS']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=attack_types, yticklabels=attack_types)\n",
    "plt.yticks(rotation=360)\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix CLIENT 2\")\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# attack_types = ['BenignTraffic', 'DDoS-ICMP_Flood', 'DDoS-PSHACK_Flood', 'DDoS-RSTFINFlood', 'DDoS-SYN_Flood', \n",
    "#                    'DDoS-SynonymousIP_Flood', 'DDoS-TCP_Flood', 'DDoS-UDP_Flood', 'DoS-SYN_Flood', 'DoS-TCP_Flood', 'DoS-UDP_Flood']\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# Số lượng lớp (10 lớp)\n",
    "num_classes = len(attack_types)\n",
    "\n",
    "# Duyệt từng lớp để tính TP, FP, TN, FN\n",
    "for i in range(num_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    metrics.append([attack_types[i], TP, FP, TN, FN])\n",
    "\n",
    "# Chuyển thành DataFrame\n",
    "df_metrics = pd.DataFrame(metrics, columns=[\"Attack_Types\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "df_metrics.set_index(\"Attack_Types\").plot(kind=\"bar\", figsize=(12, 5), colormap=\"viridis\")\n",
    "\n",
    "# Thêm nhãn\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"TP, FP, TN, FN for Each Class CLIENT 2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "\n",
    "# Hiển thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client_0 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_dir= \"log/client_0_log/14h24p__15-04/\"\n",
    "file_names = [f\"Iteration_{index+1}.csv\" for index in range(5)]\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy= []\n",
    "loss = []\n",
    "epochs = [\"Epoch_\"+str(i) for i in range(5)]\n",
    "for i, file_name in enumerate(file_names):\n",
    "    # Đọc file CSV\n",
    "    df = pd.read_csv(file_dir + file_name)  # Đổi tên file nếu cần\n",
    "\n",
    "    # Chuyển \"NA\" thành NaN và xử lý nếu cần\n",
    "    df.replace(\"NA\", None, inplace=True)\n",
    "\n",
    "      # Đảm bảo epoch là số nguyên\n",
    "    df[\"accuracy\"] = df[\"accuracy\"].astype(float)\n",
    "    df[\"loss\"] = df[\"loss\"].astype(float)\n",
    "    accuracy.append(df[\"accuracy\"])\n",
    "    loss.append(df[\"loss\"])\n",
    "    print(\"Iteration \"+str(i)+\": \")\n",
    "    for epoch_index,  epoch in enumerate(epochs):\n",
    "        print(epoch + f\": Accuracy: {df['accuracy'][epoch_index]} \\t Loss: {df['loss'][epoch_index]}\")\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Vẽ Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, accuracy[i], marker=\"o\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "    \n",
    "plt.title(\"Accuracy over Epochs Client 1\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Vẽ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, loss[i], marker=\"s\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client_1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_dir= \"log/client_1_log/14h24p__15-04/\"\n",
    "file_names = [f\"Iteration_{index+1}.csv\" for index in range(5)]\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy= []\n",
    "loss = []\n",
    "epochs = [\"Epoch_\"+str(i) for i in range(5)]\n",
    "for i, file_name in enumerate(file_names):\n",
    "    # Đọc file CSV\n",
    "    df = pd.read_csv(file_dir + file_name)  # Đổi tên file nếu cần\n",
    "\n",
    "    # Chuyển \"NA\" thành NaN và xử lý nếu cần\n",
    "    df.replace(\"NA\", None, inplace=True)\n",
    "\n",
    "      # Đảm bảo epoch là số nguyên\n",
    "    df[\"accuracy\"] = df[\"accuracy\"].astype(float)\n",
    "    df[\"loss\"] = df[\"loss\"].astype(float)\n",
    "    accuracy.append(df[\"accuracy\"])\n",
    "    loss.append(df[\"loss\"])\n",
    "    print(\"Iteration \"+str(i)+\": \")\n",
    "    for epoch_index,  epoch in enumerate(epochs):\n",
    "        print(epoch + f\": Accuracy: {df['accuracy'][epoch_index]} \\t Loss: {df['loss'][epoch_index]}\")\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Vẽ Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, accuracy[i], marker=\"o\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "    \n",
    "plt.title(\"Accuracy over Epochs Client 1\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Vẽ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, loss[i], marker=\"s\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "\n",
    "plt.title(\"Loss over Epochs Client 1\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client_2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_dir= \"log/client_2_log/14h24p__15-04/\"\n",
    "file_names = [f\"Iteration_{index+1}.csv\" for index in range(5)]\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy= []\n",
    "loss = []\n",
    "epochs = [\"Epoch_\"+str(i) for i in range(5)]\n",
    "for i, file_name in enumerate(file_names):\n",
    "    # Đọc file CSV\n",
    "    df = pd.read_csv(file_dir + file_name)  # Đổi tên file nếu cần\n",
    "\n",
    "    # Chuyển \"NA\" thành NaN và xử lý nếu cần\n",
    "    df.replace(\"NA\", None, inplace=True)\n",
    "\n",
    "      # Đảm bảo epoch là số nguyên\n",
    "    df[\"accuracy\"] = df[\"accuracy\"].astype(float)\n",
    "    df[\"loss\"] = df[\"loss\"].astype(float)\n",
    "    accuracy.append(df[\"accuracy\"])\n",
    "    loss.append(df[\"loss\"])\n",
    "    print(\"Iteration \"+str(i)+\": \")\n",
    "    for epoch_index,  epoch in enumerate(epochs):\n",
    "        print(epoch + f\": Accuracy: {df['accuracy'][epoch_index]} \\t Loss: {df['loss'][epoch_index]}\")\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Vẽ Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, accuracy[i], marker=\"o\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "    \n",
    "plt.title(\"Accuracy over Epochs _Client 2\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Vẽ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(3):\n",
    "    plt.plot(epochs, loss[i], marker=\"s\", linestyle=\"-\", label=f\"Iteration {i+1}\")\n",
    "\n",
    "plt.title(\"Loss over Epochs Client 2\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
